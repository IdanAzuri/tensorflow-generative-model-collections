2018-06-04 16:33:04.840374: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1105] Found device 0 with properties: 
name: Tesla P100-SXM2-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.4805
pciBusID: 0003:01:00.0
totalMemory: 15.90GiB freeMemory: 15.61GiB
2018-06-04 16:33:04.840869: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1195] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla P100-SXM2-16GB, pci bus id: 0003:01:00.0, compute capability: 6.0)
2018-06-04 16:33:19.158553: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1195] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla P100-SXM2-16GB, pci bus id: 0003:01:00.0, compute capability: 6.0)
/usr/lib/python3/dist-packages/numpy/core/machar.py:127: RuntimeWarning: overflow encountered in add
  a = a + a
/usr/lib/python3/dist-packages/numpy/core/machar.py:129: RuntimeWarning: invalid value encountered in subtract
  temp1 = temp - a
/usr/lib/python3/dist-packages/numpy/core/machar.py:138: RuntimeWarning: invalid value encountered in subtract
  itemp = int_conv(temp-a)
/usr/lib/python3/dist-packages/numpy/core/machar.py:162: RuntimeWarning: overflow encountered in add
  a = a + a
/usr/lib/python3/dist-packages/numpy/core/machar.py:164: RuntimeWarning: invalid value encountered in subtract
  temp1 = temp - a
/usr/lib/python3/dist-packages/numpy/core/machar.py:171: RuntimeWarning: invalid value encountered in subtract
  if any(temp-a != zero):
model has been loaded from fashion-mnist_classifier.pkl
Saving graph to: logs/fashion-mnist/train
---------
Variables: name (type shape) [size]
---------
Variable:0 (float32_ref 5x5x1x32) [800, bytes: 3200]
Variable_1:0 (float32_ref 32) [32, bytes: 128]
Variable_2:0 (float32_ref 5x5x32x64) [51200, bytes: 204800]
Variable_3:0 (float32_ref 64) [64, bytes: 256]
Variable_4:0 (float32_ref 3136x1024) [3211264, bytes: 12845056]
Variable_5:0 (float32_ref 1024) [1024, bytes: 4096]
Variable_6:0 (float32_ref 1024x10) [10240, bytes: 40960]
Variable_7:0 (float32_ref 10) [10, bytes: 40]
discriminator/d_conv1/w:0 (float32_ref 4x4x1x64) [1024, bytes: 4096]
discriminator/d_conv1/biases:0 (float32_ref 64) [64, bytes: 256]
discriminator/d_conv2/w:0 (float32_ref 4x4x64x128) [131072, bytes: 524288]
discriminator/d_conv2/biases:0 (float32_ref 128) [128, bytes: 512]
discriminator/d_bn2/beta:0 (float32_ref 128) [128, bytes: 512]
discriminator/d_bn2/gamma:0 (float32_ref 128) [128, bytes: 512]
discriminator/d_fc3/Matrix:0 (float32_ref 6272x1024) [6422528, bytes: 25690112]
discriminator/d_fc3/bias:0 (float32_ref 1024) [1024, bytes: 4096]
discriminator/d_bn3/beta:0 (float32_ref 1024) [1024, bytes: 4096]
discriminator/d_bn3/gamma:0 (float32_ref 1024) [1024, bytes: 4096]
discriminator/d_fc4/Matrix:0 (float32_ref 1024x1) [1024, bytes: 4096]
discriminator/d_fc4/bias:0 (float32_ref 1) [1, bytes: 4]
generator/g_fc1/Matrix:0 (float32_ref 74x1024) [75776, bytes: 303104]
generator/g_fc1/bias:0 (float32_ref 1024) [1024, bytes: 4096]
generator/g_bn1/beta:0 (float32_ref 1024) [1024, bytes: 4096]
generator/g_bn1/gamma:0 (float32_ref 1024) [1024, bytes: 4096]
generator/g_fc2/Matrix:0 (float32_ref 1024x6272) [6422528, bytes: 25690112]
generator/g_fc2/bias:0 (float32_ref 6272) [6272, bytes: 25088]
generator/g_bn2/beta:0 (float32_ref 6272) [6272, bytes: 25088]
generator/g_bn2/gamma:0 (float32_ref 6272) [6272, bytes: 25088]
generator/g_dc3/w:0 (float32_ref 4x4x64x128) [131072, bytes: 524288]
generator/g_dc3/biases:0 (float32_ref 64) [64, bytes: 256]
generator/g_bn3/beta:0 (float32_ref 64) [64, bytes: 256]
generator/g_bn3/gamma:0 (float32_ref 64) [64, bytes: 256]
generator/g_dc4/w:0 (float32_ref 4x4x1x64) [1024, bytes: 4096]
generator/g_dc4/biases:0 (float32_ref 1) [1, bytes: 4]
classifier/c_fc1/Matrix:0 (float32_ref 1024x64) [65536, bytes: 262144]
classifier/c_fc1/bias:0 (float32_ref 64) [64, bytes: 256]
classifier/c_bn1/beta:0 (float32_ref 64) [64, bytes: 256]
classifier/c_bn1/gamma:0 (float32_ref 64) [64, bytes: 256]
classifier/c_fc2/Matrix:0 (float32_ref 64x12) [768, bytes: 3072]
classifier/c_fc2/bias:0 (float32_ref 12) [12, bytes: 48]
Total size of variables: 16552792
Total bytes of variables: 66211168
 [*] Reading checkpoints...
 [*] Success to read MultiModalInfoGAN.model-43721
 [*] Load SUCCESS
 [*] Training finished!
step 39: accuracy:0.109375, confidence:0.9286248087882996, loss:101.9412841796875
 [*] Testing finished!
2018-06-04 16:35:31.823678: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1105] Found device 0 with properties: 
name: Tesla P100-SXM2-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.4805
pciBusID: 0003:01:00.0
totalMemory: 15.90GiB freeMemory: 15.61GiB
2018-06-04 16:35:31.849797: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1195] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla P100-SXM2-16GB, pci bus id: 0003:01:00.0, compute capability: 6.0)
/usr/lib/python3/dist-packages/numpy/core/machar.py:127: RuntimeWarning: overflow encountered in add
  a = a + a
/usr/lib/python3/dist-packages/numpy/core/machar.py:129: RuntimeWarning: invalid value encountered in subtract
  temp1 = temp - a
/usr/lib/python3/dist-packages/numpy/core/machar.py:138: RuntimeWarning: invalid value encountered in subtract
  itemp = int_conv(temp-a)
/usr/lib/python3/dist-packages/numpy/core/machar.py:162: RuntimeWarning: overflow encountered in add
  a = a + a
/usr/lib/python3/dist-packages/numpy/core/machar.py:164: RuntimeWarning: invalid value encountered in subtract
  temp1 = temp - a
/usr/lib/python3/dist-packages/numpy/core/machar.py:171: RuntimeWarning: invalid value encountered in subtract
  if any(temp-a != zero):
model has been loaded from mnist_classifier.pkl
Saving graph to: logs/mnist/train
argmax:[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3
 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]
step 0: accuracy:0.10000000149011612, confidence:0.815693736076355, loss:3.8439581394195557
[ 0  0  0 60]
argmax:[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]
step 0: accuracy:0.10000000149011612, confidence:0.8827527761459351, loss:4.840851306915283
[ 0  0 60]
argmax:[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]
step 0: accuracy:0.10000000149011612, confidence:0.3012050688266754, loss:3.377305507659912
[60]
argmax:[8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8
 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]
step 0: accuracy:0.10000000149011612, confidence:0.7609735131263733, loss:4.530697822570801
[ 0  0  0  0  0  0  0  0 60]
argmax:[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]
step 0: accuracy:0.10000000149011612, confidence:0.4613405168056488, loss:4.029476165771484
[60]
argmax:[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]
step 0: accuracy:0.10000000149011612, confidence:0.9710252285003662, loss:6.869191646575928
[ 0  0 60]
argmax:[8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8
 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]
step 0: accuracy:0.10000000149011612, confidence:0.6740121245384216, loss:3.6909799575805664
[ 0  0  0  0  0  0  0  0 60]
argmax:[8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8
 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]
step 0: accuracy:0.10000000149011612, confidence:0.4293002784252167, loss:3.2059035301208496
[ 0  0  0  0  0  0  0  0 60]
argmax:[8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8
 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]
step 0: accuracy:0.10000000149011612, confidence:0.8946425914764404, loss:4.292015552520752
[ 0  0  0  0  0  0  0  0 60]
argmax:[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]
step 0: accuracy:0.10000000149011612, confidence:0.513565719127655, loss:3.8904316425323486
[60]
2018-06-04 16:35:47.558652: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1105] Found device 0 with properties: 
name: Tesla P100-SXM2-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.4805
pciBusID: 0003:01:00.0
totalMemory: 15.90GiB freeMemory: 15.61GiB
2018-06-04 16:35:47.579030: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1195] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla P100-SXM2-16GB, pci bus id: 0003:01:00.0, compute capability: 6.0)
/usr/lib/python3/dist-packages/numpy/core/machar.py:127: RuntimeWarning: overflow encountered in add
  a = a + a
/usr/lib/python3/dist-packages/numpy/core/machar.py:129: RuntimeWarning: invalid value encountered in subtract
  temp1 = temp - a
/usr/lib/python3/dist-packages/numpy/core/machar.py:138: RuntimeWarning: invalid value encountered in subtract
  itemp = int_conv(temp-a)
/usr/lib/python3/dist-packages/numpy/core/machar.py:162: RuntimeWarning: overflow encountered in add
  a = a + a
/usr/lib/python3/dist-packages/numpy/core/machar.py:164: RuntimeWarning: invalid value encountered in subtract
  temp1 = temp - a
/usr/lib/python3/dist-packages/numpy/core/machar.py:171: RuntimeWarning: invalid value encountered in subtract
  if any(temp-a != zero):
Saving graph to: logs/fashion-mnist_MultivariateGaussianSampler_train
step 0: accuracy:0.10300000011920929, confidence:0.9975219964981079, loss:12.212081909179688
epoch0: step0/160
step 0: accuracy:0.12700000405311584, confidence:0.8045125007629395, loss:8.212767601013184
epoch0: step100/160
step 0: accuracy:0.13600000739097595, confidence:0.8085570335388184, loss:8.353377342224121
epoch1: step0/160
step 100: accuracy:0.15000000596046448, confidence:0.7990909814834595, loss:7.942030906677246
epoch1: step100/160
step 0: accuracy:0.11999999731779099, confidence:0.8395578861236572, loss:8.53017520904541
epoch2: step0/160
step 200: accuracy:0.16500000655651093, confidence:0.8115895986557007, loss:8.118307113647461
epoch2: step100/160
step 0: accuracy:0.1459999978542328, confidence:0.7968690395355225, loss:7.871705055236816
epoch3: step0/160
step 300: accuracy:0.1589999943971634, confidence:0.8231135010719299, loss:8.047212600708008
epoch3: step100/160
step 0: accuracy:0.16300000250339508, confidence:0.8110394477844238, loss:7.734137535095215
epoch4: step0/160
step 400: accuracy:0.1379999965429306, confidence:0.7942746877670288, loss:7.816262245178223
epoch4: step100/160
step 0: accuracy:0.14800000190734863, confidence:0.8075021505355835, loss:8.0059232711792
epoch5: step0/160
step 500: accuracy:0.15000000596046448, confidence:0.8213372826576233, loss:8.054876327514648
epoch5: step100/160
step 0: accuracy:0.17000000178813934, confidence:0.804139256477356, loss:7.562093257904053
epoch6: step0/160
step 600: accuracy:0.164000004529953, confidence:0.8153873085975647, loss:7.552517414093018
epoch6: step100/160
step 0: accuracy:0.1679999977350235, confidence:0.7904793620109558, loss:7.557621479034424
epoch7: step0/160
step 700: accuracy:0.17499999701976776, confidence:0.8069908618927002, loss:7.627206802368164
epoch7: step100/160
step 0: accuracy:0.17299999296665192, confidence:0.8164259195327759, loss:7.591607570648193
epoch8: step0/160
step 800: accuracy:0.15199999511241913, confidence:0.8259195685386658, loss:8.101065635681152
epoch8: step100/160
step 0: accuracy:0.1599999964237213, confidence:0.8141687512397766, loss:7.604971885681152
epoch9: step0/160
step 900: accuracy:0.14900000393390656, confidence:0.8086807131767273, loss:7.718348503112793
epoch9: step100/160
step 0: accuracy:0.15299999713897705, confidence:0.8167916536331177, loss:7.707694053649902
epoch10: step0/160
step 1000: accuracy:0.1809999942779541, confidence:0.8107710480690002, loss:7.5417890548706055
epoch10: step100/160
step 0: accuracy:0.15800000727176666, confidence:0.8228111863136292, loss:7.6507415771484375
epoch11: step0/160
step 1100: accuracy:0.16300000250339508, confidence:0.8094465136528015, loss:7.486055374145508
epoch11: step100/160
step 0: accuracy:0.13899999856948853, confidence:0.8279199600219727, loss:7.997608661651611
epoch12: step0/160
step 1200: accuracy:0.1889999955892563, confidence:0.8099384903907776, loss:7.226013660430908
epoch12: step100/160
step 0: accuracy:0.15299999713897705, confidence:0.8093127608299255, loss:7.363129138946533
epoch13: step0/160
step 1300: accuracy:0.1550000011920929, confidence:0.822357714176178, loss:7.513706684112549
epoch13: step100/160
step 0: accuracy:0.16099999845027924, confidence:0.851196825504303, loss:7.838701248168945
epoch14: step0/160
step 1400: accuracy:0.17900000512599945, confidence:0.8220359683036804, loss:7.458000659942627
epoch14: step100/160
step 0: accuracy:0.19599999487400055, confidence:0.8176220655441284, loss:7.284977436065674
epoch15: step0/160
step 1500: accuracy:0.17399999499320984, confidence:0.8088623881340027, loss:7.476234436035156
epoch15: step100/160
step 0: accuracy:0.20200000703334808, confidence:0.8228036165237427, loss:7.222888469696045
epoch16: step0/160
step 1600: accuracy:0.18799999356269836, confidence:0.7986037135124207, loss:7.19246768951416
epoch16: step100/160
step 0: accuracy:0.1979999989271164, confidence:0.8182551264762878, loss:7.351719856262207
epoch17: step0/160
step 1700: accuracy:0.1770000010728836, confidence:0.8095031976699829, loss:7.199794769287109
epoch17: step100/160
step 0: accuracy:0.17100000381469727, confidence:0.8370126485824585, loss:7.576964378356934
epoch18: step0/160
step 1800: accuracy:0.1679999977350235, confidence:0.8203715085983276, loss:7.687135696411133
epoch18: step100/160
step 0: accuracy:0.19599999487400055, confidence:0.8326462507247925, loss:7.182112693786621
epoch19: step0/160
step 1900: accuracy:0.16300000250339508, confidence:0.8343445658683777, loss:7.55446195602417
epoch19: step100/160
step 0: accuracy:0.19099999964237213, confidence:0.8379461765289307, loss:7.468016147613525
epoch20: step0/160
step 2000: accuracy:0.19300000369548798, confidence:0.8057114481925964, loss:7.1493964195251465
epoch20: step100/160
step 0: accuracy:0.20399999618530273, confidence:0.8310838341712952, loss:7.023918151855469
epoch21: step0/160
step 2100: accuracy:0.1899999976158142, confidence:0.8387326002120972, loss:7.446560859680176
epoch21: step100/160
step 0: accuracy:0.20100000500679016, confidence:0.8270741701126099, loss:7.099157333374023
epoch22: step0/160
step 2200: accuracy:0.1940000057220459, confidence:0.8273013830184937, loss:7.024527549743652
epoch22: step100/160
step 0: accuracy:0.20200000703334808, confidence:0.8382376432418823, loss:7.140932559967041
epoch23: step0/160
step 2300: accuracy:0.1899999976158142, confidence:0.8190388679504395, loss:7.085176467895508
epoch23: step100/160
step 0: accuracy:0.1899999976158142, confidence:0.8167917132377625, loss:6.9458327293396
epoch24: step0/160
step 2400: accuracy:0.20000000298023224, confidence:0.813338577747345, loss:6.892943859100342
epoch24: step100/160
step 0: accuracy:0.18199999630451202, confidence:0.8486887216567993, loss:7.418209075927734
epoch25: step0/160
step 2500: accuracy:0.21699999272823334, confidence:0.8057805299758911, loss:6.646256923675537
epoch25: step100/160
step 0: accuracy:0.20399999618530273, confidence:0.8356820344924927, loss:6.994350910186768
epoch26: step0/160
step 2600: accuracy:0.19900000095367432, confidence:0.8544792532920837, loss:6.895811557769775
epoch26: step100/160
step 0: accuracy:0.19200000166893005, confidence:0.8569207787513733, loss:7.222175121307373
epoch27: step0/160
step 2700: accuracy:0.19900000095367432, confidence:0.8342081308364868, loss:6.953344345092773
epoch27: step100/160
step 0: accuracy:0.210999995470047, confidence:0.838183581829071, loss:6.844040393829346
epoch28: step0/160
step 2800: accuracy:0.2280000001192093, confidence:0.8401068449020386, loss:6.695497989654541
epoch28: step100/160
step 0: accuracy:0.22200000286102295, confidence:0.8595393896102905, loss:6.988290786743164
epoch29: step0/160
step 2900: accuracy:0.20900000631809235, confidence:0.8103015422821045, loss:6.724559783935547
epoch29: step100/160
step 0: accuracy:0.1979999989271164, confidence:0.8461266160011292, loss:6.9897780418396
epoch30: step0/160
step 3000: accuracy:0.2240000069141388, confidence:0.8399651050567627, loss:6.698463439941406
epoch30: step100/160
step 0: accuracy:0.19300000369548798, confidence:0.8476223349571228, loss:7.24992561340332
epoch31: step0/160
step 3100: accuracy:0.19900000095367432, confidence:0.8385925889015198, loss:6.977023124694824
epoch31: step100/160
step 0: accuracy:0.20900000631809235, confidence:0.849778413772583, loss:6.832876205444336
epoch32: step0/160
step 3200: accuracy:0.24300000071525574, confidence:0.8275266289710999, loss:6.4313249588012695
epoch32: step100/160
step 0: accuracy:0.19200000166893005, confidence:0.8468992710113525, loss:7.107282638549805
epoch33: step0/160
step 3300: accuracy:0.2199999988079071, confidence:0.8523145914077759, loss:6.978144645690918
epoch33: step100/160
step 0: accuracy:0.2160000056028366, confidence:0.838093101978302, loss:6.71163272857666
epoch34: step0/160
step 3400: accuracy:0.20399999618530273, confidence:0.8254212737083435, loss:6.873677730560303
epoch34: step100/160
step 0: accuracy:0.22100000083446503, confidence:0.8570706248283386, loss:6.821173191070557
epoch35: step0/160
step 3500: accuracy:0.20399999618530273, confidence:0.8594913482666016, loss:7.213860034942627
epoch35: step100/160
step 0: accuracy:0.18799999356269836, confidence:0.8431143760681152, loss:7.20144510269165
epoch36: step0/160
step 3600: accuracy:0.22200000286102295, confidence:0.8390702605247498, loss:6.758777618408203
epoch36: step100/160
step 0: accuracy:0.2240000069141388, confidence:0.85240638256073, loss:6.774411201477051
epoch37: step0/160
step 3700: accuracy:0.21299999952316284, confidence:0.846333920955658, loss:6.904953956604004
epoch37: step100/160
step 0: accuracy:0.23199999332427979, confidence:0.8360514044761658, loss:6.603928565979004
epoch38: step0/160
step 3800: accuracy:0.19699999690055847, confidence:0.823040783405304, loss:6.234314918518066
epoch38: step100/160
step 0: accuracy:0.2160000056028366, confidence:0.8610640168190002, loss:6.576769828796387
epoch39: step0/160
step 3900: accuracy:0.22100000083446503, confidence:0.8654996752738953, loss:6.438769340515137
epoch39: step100/160
step 0: accuracy:0.2240000069141388, confidence:0.8626512885093689, loss:6.4611287117004395
epoch40: step0/160
step 4000: accuracy:0.20499999821186066, confidence:0.8710482120513916, loss:6.477402210235596
epoch40: step100/160
step 0: accuracy:0.19300000369548798, confidence:0.8747724890708923, loss:6.752419948577881
epoch41: step0/160
step 4100: accuracy:0.2150000035762787, confidence:0.8720747828483582, loss:6.543757915496826
epoch41: step100/160
step 0: accuracy:0.21299999952316284, confidence:0.8795149922370911, loss:6.587671279907227
epoch42: step0/160
step 4200: accuracy:0.22499999403953552, confidence:0.8757956624031067, loss:6.329146385192871
epoch42: step100/160
step 0: accuracy:0.2290000021457672, confidence:0.8684190511703491, loss:6.347327709197998
epoch43: step0/160
step 4300: accuracy:0.2160000056028366, confidence:0.871024489402771, loss:6.622041702270508
epoch43: step100/160
step 0: accuracy:0.21799999475479126, confidence:0.8744570016860962, loss:6.414902687072754
epoch44: step0/160
step 4400: accuracy:0.21299999952316284, confidence:0.865572452545166, loss:6.7444024085998535
epoch44: step100/160
step 0: accuracy:0.2199999988079071, confidence:0.8717681765556335, loss:6.563838958740234
epoch45: step0/160
step 4500: accuracy:0.21400000154972076, confidence:0.8677287697792053, loss:6.714460849761963
epoch45: step100/160
step 0: accuracy:0.20200000703334808, confidence:0.8689653277397156, loss:6.7318902015686035
epoch46: step0/160
step 4600: accuracy:0.20900000631809235, confidence:0.8723253011703491, loss:6.543820381164551
epoch46: step100/160
step 0: accuracy:0.2280000001192093, confidence:0.865450918674469, loss:6.590471267700195
epoch47: step0/160
step 4700: accuracy:0.22499999403953552, confidence:0.8690296411514282, loss:6.498681545257568
epoch47: step100/160
step 0: accuracy:0.2329999953508377, confidence:0.8674289584159851, loss:6.5121378898620605
epoch48: step0/160
step 4800: accuracy:0.23399999737739563, confidence:0.8743500113487244, loss:6.551486492156982
epoch48: step100/160
step 0: accuracy:0.23199999332427979, confidence:0.8649193048477173, loss:6.464782238006592
epoch49: step0/160
step 4900: accuracy:0.2280000001192093, confidence:0.8572848439216614, loss:6.538198947906494
epoch49: step100/160
step 0: accuracy:0.22200000286102295, confidence:0.8682461977005005, loss:6.805141448974609
epoch50: step0/160
step 5000: accuracy:0.2329999953508377, confidence:0.8531128168106079, loss:6.505993366241455
epoch50: step100/160
step 0: accuracy:0.20200000703334808, confidence:0.8608942031860352, loss:6.693296432495117
epoch51: step0/160
step 5100: accuracy:0.21899999678134918, confidence:0.867205023765564, loss:6.804088115692139
epoch51: step100/160
step 0: accuracy:0.21299999952316284, confidence:0.8707347512245178, loss:7.052334308624268
epoch52: step0/160
step 5200: accuracy:0.21899999678134918, confidence:0.8591628670692444, loss:6.778909206390381
epoch52: step100/160
step 0: accuracy:0.18799999356269836, confidence:0.8571068048477173, loss:6.9817914962768555
epoch53: step0/160
step 5300: accuracy:0.2160000056028366, confidence:0.8522061705589294, loss:6.755094051361084
epoch53: step100/160
step 0: accuracy:0.21400000154972076, confidence:0.8655280470848083, loss:6.861591815948486
epoch54: step0/160
step 5400: accuracy:0.22100000083446503, confidence:0.8388100862503052, loss:6.594751834869385
epoch54: step100/160
step 0: accuracy:0.24400000274181366, confidence:0.8653210401535034, loss:6.525315761566162
epoch55: step0/160
step 5500: accuracy:0.2240000069141388, confidence:0.8557041883468628, loss:6.783445835113525
epoch55: step100/160
step 0: accuracy:0.21400000154972076, confidence:0.852698564529419, loss:6.782183647155762
epoch56: step0/160
step 5600: accuracy:0.25099998712539673, confidence:0.8548250794410706, loss:6.55497932434082
epoch56: step100/160
step 0: accuracy:0.20900000631809235, confidence:0.8676856160163879, loss:7.072892665863037
epoch57: step0/160
step 5700: accuracy:0.25099998712539673, confidence:0.859179675579071, loss:6.546792030334473
epoch57: step100/160
step 0: accuracy:0.22100000083446503, confidence:0.8669450283050537, loss:6.84190559387207
epoch58: step0/160
step 5800: accuracy:0.21799999475479126, confidence:0.865006148815155, loss:6.890316009521484
epoch58: step100/160
step 0: accuracy:0.20900000631809235, confidence:0.8725888133049011, loss:7.048374652862549
epoch59: step0/160
step 5900: accuracy:0.2290000021457672, confidence:0.8493017554283142, loss:6.617485046386719
epoch59: step100/160
step 0: accuracy:0.23600000143051147, confidence:0.8573222160339355, loss:6.630837917327881
epoch60: step0/160
step 6000: accuracy:0.2199999988079071, confidence:0.8537823557853699, loss:6.796630859375
epoch60: step100/160
step 0: accuracy:0.20200000703334808, confidence:0.8499311804771423, loss:7.005737781524658
epoch61: step0/160
step 6100: accuracy:0.22100000083446503, confidence:0.853989839553833, loss:6.7809014320373535
epoch61: step100/160
step 0: accuracy:0.2460000067949295, confidence:0.862180233001709, loss:6.617705345153809
epoch62: step0/160
step 6200: accuracy:0.20800000429153442, confidence:0.8563641309738159, loss:6.90525484085083
epoch62: step100/160
step 0: accuracy:0.2529999911785126, confidence:0.8638592958450317, loss:6.647254943847656
epoch63: step0/160
step 6300: accuracy:0.21400000154972076, confidence:0.8598905205726624, loss:6.97783088684082
epoch63: step100/160
step 0: accuracy:0.23800000548362732, confidence:0.8521814942359924, loss:6.610884189605713
epoch64: step0/160
step 6400: accuracy:0.19099999964237213, confidence:0.8554266095161438, loss:7.033870220184326
epoch64: step100/160
step 0: accuracy:0.22200000286102295, confidence:0.8481703400611877, loss:6.799878120422363
epoch65: step0/160
step 6500: accuracy:0.2329999953508377, confidence:0.8704173564910889, loss:6.840878963470459
epoch65: step100/160
step 0: accuracy:0.20999999344348907, confidence:0.863006055355072, loss:7.056504726409912
epoch66: step0/160
step 6600: accuracy:0.22599999606609344, confidence:0.8505403399467468, loss:6.9035420417785645
epoch66: step100/160
step 0: accuracy:0.2160000056028366, confidence:0.8704774379730225, loss:7.164121627807617
epoch67: step0/160
step 6700: accuracy:0.2160000056028366, confidence:0.8530998826026917, loss:6.992044448852539
epoch67: step100/160
step 0: accuracy:0.19300000369548798, confidence:0.8627502918243408, loss:7.459457874298096
epoch68: step0/160
step 6800: accuracy:0.21899999678134918, confidence:0.8622769117355347, loss:7.014633655548096
epoch68: step100/160
step 0: accuracy:0.22100000083446503, confidence:0.8587827682495117, loss:6.750600814819336
epoch69: step0/160
step 6900: accuracy:0.23800000548362732, confidence:0.8784949779510498, loss:7.064403533935547
epoch69: step100/160
step 0: accuracy:0.21299999952316284, confidence:0.8748553395271301, loss:7.225180149078369
epoch70: step0/160
step 7000: accuracy:0.20399999618530273, confidence:0.8634627461433411, loss:7.264021396636963
epoch70: step100/160
step 0: accuracy:0.18799999356269836, confidence:0.8672400116920471, loss:7.401978015899658
epoch71: step0/160
step 7100: accuracy:0.23100000619888306, confidence:0.8573513031005859, loss:6.913928031921387
epoch71: step100/160
step 0: accuracy:0.1979999989271164, confidence:0.765438973903656, loss:6.1866021156311035
epoch72: step0/160
step 7200: accuracy:0.19099999964237213, confidence:0.8467971086502075, loss:6.7446465492248535
epoch72: step100/160
step 0: accuracy:0.16500000655651093, confidence:0.8630883097648621, loss:7.082682132720947
epoch73: step0/160
step 7300: accuracy:0.21299999952316284, confidence:0.8648514151573181, loss:6.638091564178467
epoch73: step100/160
step 0: accuracy:0.22200000286102295, confidence:0.8630443215370178, loss:6.739231586456299
epoch74: step0/160
step 7400: accuracy:0.20999999344348907, confidence:0.8623239398002625, loss:6.825869083404541
epoch74: step100/160
step 0: accuracy:0.23000000417232513, confidence:0.8619697093963623, loss:6.5417304039001465
epoch75: step0/160
step 7500: accuracy:0.20499999821186066, confidence:0.864382803440094, loss:6.779017925262451
epoch75: step100/160
step 0: accuracy:0.20499999821186066, confidence:0.8597061634063721, loss:6.717597007751465
epoch76: step0/160
step 7600: accuracy:0.20499999821186066, confidence:0.8625767827033997, loss:6.842414855957031
epoch76: step100/160
step 0: accuracy:0.19099999964237213, confidence:0.8675129413604736, loss:7.044126510620117
epoch77: step0/160
step 7700: accuracy:0.210999995470047, confidence:0.868754506111145, loss:6.928243637084961
epoch77: step100/160
step 0: accuracy:0.22100000083446503, confidence:0.861627459526062, loss:6.686897277832031
epoch78: step0/160
step 7800: accuracy:0.21899999678134918, confidence:0.8542649149894714, loss:6.794991970062256
epoch78: step100/160
step 0: accuracy:0.2280000001192093, confidence:0.8597567081451416, loss:6.706065654754639
epoch79: step0/160
step 7900: accuracy:0.23499999940395355, confidence:0.8639254570007324, loss:6.852629661560059
epoch79: step100/160
step 0: accuracy:0.20900000631809235, confidence:0.8592222929000854, loss:6.909249782562256
epoch80: step0/160
step 8000: accuracy:0.23999999463558197, confidence:0.8503056168556213, loss:6.628767490386963
epoch80: step100/160
step 0: accuracy:0.2240000069141388, confidence:0.8627912998199463, loss:7.005285263061523
epoch81: step0/160
step 8100: accuracy:0.21299999952316284, confidence:0.8513296842575073, loss:6.801934719085693
epoch81: step100/160
step 0: accuracy:0.22200000286102295, confidence:0.8606950640678406, loss:6.815054416656494
epoch82: step0/160
step 8200: accuracy:0.21799999475479126, confidence:0.858437716960907, loss:6.876260280609131
epoch82: step100/160
step 0: accuracy:0.18400000035762787, confidence:0.8518544435501099, loss:7.30742883682251
epoch83: step0/160
step 8300: accuracy:0.20800000429153442, confidence:0.8519062995910645, loss:7.123867511749268
epoch83: step100/160
step 0: accuracy:0.21699999272823334, confidence:0.8635305762290955, loss:7.003730297088623
epoch84: step0/160
step 8400: accuracy:0.20800000429153442, confidence:0.8517959713935852, loss:6.886446475982666
epoch84: step100/160
step 0: accuracy:0.20499999821186066, confidence:0.857460081577301, loss:7.130523204803467
epoch85: step0/160
step 8500: accuracy:0.21400000154972076, confidence:0.8484852910041809, loss:7.000414848327637
epoch85: step100/160
step 0: accuracy:0.2029999941587448, confidence:0.8607379794120789, loss:7.185406684875488
epoch86: step0/160
step 8600: accuracy:0.2280000001192093, confidence:0.8567579984664917, loss:7.032930850982666
epoch86: step100/160
step 0: accuracy:0.2329999953508377, confidence:0.8530930280685425, loss:6.782618999481201
epoch87: step0/160
step 8700: accuracy:0.20999999344348907, confidence:0.8482078313827515, loss:6.994138717651367
epoch87: step100/160
step 0: accuracy:0.2280000001192093, confidence:0.8623674511909485, loss:6.90691614151001
epoch88: step0/160
step 8800: accuracy:0.2199999988079071, confidence:0.8500930070877075, loss:6.981985569000244
epoch88: step100/160
step 0: accuracy:0.2240000069141388, confidence:0.8627442121505737, loss:6.807926177978516
epoch89: step0/160
step 8900: accuracy:0.2029999941587448, confidence:0.8384241461753845, loss:7.01980447769165
epoch89: step100/160
step 0: accuracy:0.20000000298023224, confidence:0.8536755442619324, loss:7.144961357116699
epoch90: step0/160
step 9000: accuracy:0.24899999797344208, confidence:0.850886881351471, loss:6.734748840332031
epoch90: step100/160
step 0: accuracy:0.20200000703334808, confidence:0.8439021110534668, loss:7.001962184906006
epoch91: step0/160
step 9100: accuracy:0.20999999344348907, confidence:0.8458092212677002, loss:7.077414512634277
epoch91: step100/160
step 0: accuracy:0.2160000056028366, confidence:0.8558899164199829, loss:7.079841613769531
epoch92: step0/160
step 9200: accuracy:0.23600000143051147, confidence:0.8385843634605408, loss:6.746077060699463
epoch92: step100/160
step 0: accuracy:0.23100000619888306, confidence:0.8581133484840393, loss:6.763762474060059
epoch93: step0/160
step 9300: accuracy:0.2280000001192093, confidence:0.8452081084251404, loss:6.897193431854248
epoch93: step100/160
step 0: accuracy:0.23999999463558197, confidence:0.8493441343307495, loss:6.528680324554443
epoch94: step0/160
step 9400: accuracy:0.23000000417232513, confidence:0.8393633365631104, loss:6.792173385620117
epoch94: step100/160
step 0: accuracy:0.22200000286102295, confidence:0.8494502902030945, loss:6.943584442138672
epoch95: step0/160
step 9500: accuracy:0.20100000500679016, confidence:0.84488844871521, loss:7.135310649871826
epoch95: step100/160
step 0: accuracy:0.22599999606609344, confidence:0.8534349799156189, loss:7.050281524658203
epoch96: step0/160
step 9600: accuracy:0.20399999618530273, confidence:0.8535618782043457, loss:7.083464622497559
epoch96: step100/160
step 0: accuracy:0.2070000022649765, confidence:0.850702702999115, loss:7.05502462387085
epoch97: step0/160
step 9700: accuracy:0.19300000369548798, confidence:0.8482583165168762, loss:7.363584995269775
epoch97: step100/160
step 0: accuracy:0.2199999988079071, confidence:0.8659161329269409, loss:7.135871887207031
epoch98: step0/160
step 9800: accuracy:0.20999999344348907, confidence:0.8521462678909302, loss:7.05680513381958
epoch98: step100/160
step 0: accuracy:0.2029999941587448, confidence:0.8537589907646179, loss:7.279761791229248
epoch99: step0/160
step 9900: accuracy:0.22699999809265137, confidence:0.8562964200973511, loss:6.898138523101807
epoch99: step100/160
