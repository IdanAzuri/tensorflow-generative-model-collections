2018-06-04 16:33:05.328947: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1105] Found device 0 with properties: 
name: Tesla P100-SXM2-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.4805
pciBusID: 0002:01:00.0
totalMemory: 15.90GiB freeMemory: 15.61GiB
2018-06-04 16:33:05.333515: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1195] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla P100-SXM2-16GB, pci bus id: 0002:01:00.0, compute capability: 6.0)
2018-06-04 16:33:19.376474: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1195] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla P100-SXM2-16GB, pci bus id: 0002:01:00.0, compute capability: 6.0)
/usr/lib/python3/dist-packages/numpy/core/machar.py:127: RuntimeWarning: overflow encountered in add
  a = a + a
/usr/lib/python3/dist-packages/numpy/core/machar.py:129: RuntimeWarning: invalid value encountered in subtract
  temp1 = temp - a
/usr/lib/python3/dist-packages/numpy/core/machar.py:138: RuntimeWarning: invalid value encountered in subtract
  itemp = int_conv(temp-a)
/usr/lib/python3/dist-packages/numpy/core/machar.py:162: RuntimeWarning: overflow encountered in add
  a = a + a
/usr/lib/python3/dist-packages/numpy/core/machar.py:164: RuntimeWarning: invalid value encountered in subtract
  temp1 = temp - a
/usr/lib/python3/dist-packages/numpy/core/machar.py:171: RuntimeWarning: invalid value encountered in subtract
  if any(temp-a != zero):
model has been loaded from fashion-mnist_classifier.pkl
Saving graph to: logs/fashion-mnist/train
---------
Variables: name (type shape) [size]
---------
Variable:0 (float32_ref 5x5x1x32) [800, bytes: 3200]
Variable_1:0 (float32_ref 32) [32, bytes: 128]
Variable_2:0 (float32_ref 5x5x32x64) [51200, bytes: 204800]
Variable_3:0 (float32_ref 64) [64, bytes: 256]
Variable_4:0 (float32_ref 3136x1024) [3211264, bytes: 12845056]
Variable_5:0 (float32_ref 1024) [1024, bytes: 4096]
Variable_6:0 (float32_ref 1024x10) [10240, bytes: 40960]
Variable_7:0 (float32_ref 10) [10, bytes: 40]
discriminator/d_conv1/w:0 (float32_ref 4x4x1x64) [1024, bytes: 4096]
discriminator/d_conv1/biases:0 (float32_ref 64) [64, bytes: 256]
discriminator/d_conv2/w:0 (float32_ref 4x4x64x128) [131072, bytes: 524288]
discriminator/d_conv2/biases:0 (float32_ref 128) [128, bytes: 512]
discriminator/d_bn2/beta:0 (float32_ref 128) [128, bytes: 512]
discriminator/d_bn2/gamma:0 (float32_ref 128) [128, bytes: 512]
discriminator/d_fc3/Matrix:0 (float32_ref 6272x1024) [6422528, bytes: 25690112]
discriminator/d_fc3/bias:0 (float32_ref 1024) [1024, bytes: 4096]
discriminator/d_bn3/beta:0 (float32_ref 1024) [1024, bytes: 4096]
discriminator/d_bn3/gamma:0 (float32_ref 1024) [1024, bytes: 4096]
discriminator/d_fc4/Matrix:0 (float32_ref 1024x1) [1024, bytes: 4096]
discriminator/d_fc4/bias:0 (float32_ref 1) [1, bytes: 4]
generator/g_fc1/Matrix:0 (float32_ref 74x1024) [75776, bytes: 303104]
generator/g_fc1/bias:0 (float32_ref 1024) [1024, bytes: 4096]
generator/g_bn1/beta:0 (float32_ref 1024) [1024, bytes: 4096]
generator/g_bn1/gamma:0 (float32_ref 1024) [1024, bytes: 4096]
generator/g_fc2/Matrix:0 (float32_ref 1024x6272) [6422528, bytes: 25690112]
generator/g_fc2/bias:0 (float32_ref 6272) [6272, bytes: 25088]
generator/g_bn2/beta:0 (float32_ref 6272) [6272, bytes: 25088]
generator/g_bn2/gamma:0 (float32_ref 6272) [6272, bytes: 25088]
generator/g_dc3/w:0 (float32_ref 4x4x64x128) [131072, bytes: 524288]
generator/g_dc3/biases:0 (float32_ref 64) [64, bytes: 256]
generator/g_bn3/beta:0 (float32_ref 64) [64, bytes: 256]
generator/g_bn3/gamma:0 (float32_ref 64) [64, bytes: 256]
generator/g_dc4/w:0 (float32_ref 4x4x1x64) [1024, bytes: 4096]
generator/g_dc4/biases:0 (float32_ref 1) [1, bytes: 4]
classifier/c_fc1/Matrix:0 (float32_ref 1024x64) [65536, bytes: 262144]
classifier/c_fc1/bias:0 (float32_ref 64) [64, bytes: 256]
classifier/c_bn1/beta:0 (float32_ref 64) [64, bytes: 256]
classifier/c_bn1/gamma:0 (float32_ref 64) [64, bytes: 256]
classifier/c_fc2/Matrix:0 (float32_ref 64x12) [768, bytes: 3072]
classifier/c_fc2/bias:0 (float32_ref 12) [12, bytes: 48]
Total size of variables: 16552792
Total bytes of variables: 66211168
 [*] Reading checkpoints...
 [*] Success to read MultiModalInfoGAN.model-43721
 [*] Load SUCCESS
 [*] Training finished!
step 39: accuracy:0.1302083283662796, confidence:0.8859676122665405, loss:102.17433166503906
 [*] Testing finished!
2018-06-04 16:34:59.042896: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1105] Found device 0 with properties: 
name: Tesla P100-SXM2-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.4805
pciBusID: 0002:01:00.0
totalMemory: 15.90GiB freeMemory: 15.61GiB
2018-06-04 16:34:59.104247: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1195] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla P100-SXM2-16GB, pci bus id: 0002:01:00.0, compute capability: 6.0)
/usr/lib/python3/dist-packages/numpy/core/machar.py:127: RuntimeWarning: overflow encountered in add
  a = a + a
/usr/lib/python3/dist-packages/numpy/core/machar.py:129: RuntimeWarning: invalid value encountered in subtract
  temp1 = temp - a
/usr/lib/python3/dist-packages/numpy/core/machar.py:138: RuntimeWarning: invalid value encountered in subtract
  itemp = int_conv(temp-a)
/usr/lib/python3/dist-packages/numpy/core/machar.py:162: RuntimeWarning: overflow encountered in add
  a = a + a
/usr/lib/python3/dist-packages/numpy/core/machar.py:164: RuntimeWarning: invalid value encountered in subtract
  temp1 = temp - a
/usr/lib/python3/dist-packages/numpy/core/machar.py:171: RuntimeWarning: invalid value encountered in subtract
  if any(temp-a != zero):
model has been loaded from mnist_classifier.pkl
Saving graph to: logs/mnist/train
argmax:[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]
step 0: accuracy:0.10000000149011612, confidence:0.699447751045227, loss:3.908726692199707
[60]
argmax:[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]
step 0: accuracy:0.10000000149011612, confidence:0.7821416854858398, loss:5.211000442504883
[ 0  0 60]
argmax:[6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6
 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6]
step 0: accuracy:0.10000000149011612, confidence:0.6292270421981812, loss:4.236948013305664
[ 0  0  0  0  0  0 60]
argmax:[8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8
 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]
step 0: accuracy:0.10000000149011612, confidence:0.7932791113853455, loss:4.216840744018555
[ 0  0  0  0  0  0  0  0 60]
argmax:[4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4
 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]
step 0: accuracy:0.10000000149011612, confidence:0.508534848690033, loss:4.47888708114624
[ 0  0  0  0 60]
argmax:[8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8
 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]
step 0: accuracy:0.10000000149011612, confidence:0.7507860660552979, loss:3.9684343338012695
[ 0  0  0  0  0  0  0  0 60]
argmax:[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]
step 0: accuracy:0.10000000149011612, confidence:0.9016553163528442, loss:5.100010871887207
[ 0  0 60]
argmax:[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3
 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]
step 0: accuracy:0.10000000149011612, confidence:0.4000917375087738, loss:3.159588575363159
[ 0  0  0 60]
argmax:[8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8
 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]
step 0: accuracy:0.10000000149011612, confidence:0.5260772109031677, loss:4.297938346862793
[ 0  0  0  0  0  0  0  0 60]
argmax:[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]
step 0: accuracy:0.10000000149011612, confidence:0.4384259581565857, loss:3.642181873321533
[60]
2018-06-04 16:35:20.787632: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1105] Found device 0 with properties: 
name: Tesla P100-SXM2-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.4805
pciBusID: 0002:01:00.0
totalMemory: 15.90GiB freeMemory: 15.61GiB
2018-06-04 16:35:20.803809: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1195] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla P100-SXM2-16GB, pci bus id: 0002:01:00.0, compute capability: 6.0)
/usr/lib/python3/dist-packages/numpy/core/machar.py:127: RuntimeWarning: overflow encountered in add
  a = a + a
/usr/lib/python3/dist-packages/numpy/core/machar.py:129: RuntimeWarning: invalid value encountered in subtract
  temp1 = temp - a
/usr/lib/python3/dist-packages/numpy/core/machar.py:138: RuntimeWarning: invalid value encountered in subtract
  itemp = int_conv(temp-a)
/usr/lib/python3/dist-packages/numpy/core/machar.py:162: RuntimeWarning: overflow encountered in add
  a = a + a
/usr/lib/python3/dist-packages/numpy/core/machar.py:164: RuntimeWarning: invalid value encountered in subtract
  temp1 = temp - a
/usr/lib/python3/dist-packages/numpy/core/machar.py:171: RuntimeWarning: invalid value encountered in subtract
  if any(temp-a != zero):
Saving graph to: logs/fashion-mnist_MultiModalUniformSample_train
step 0: accuracy:0.10700000077486038, confidence:0.8103023767471313, loss:6.408229351043701
epoch0: step0/160
step 0: accuracy:0.13699999451637268, confidence:0.6306467056274414, loss:5.158388614654541
epoch0: step100/160
step 0: accuracy:0.10599999874830246, confidence:0.6300864219665527, loss:5.146920680999756
epoch1: step0/160
step 100: accuracy:0.12999999523162842, confidence:0.6707631945610046, loss:5.394497871398926
epoch1: step100/160
step 0: accuracy:0.1120000034570694, confidence:0.6315076351165771, loss:5.241645336151123
epoch2: step0/160
step 200: accuracy:0.14499999582767487, confidence:0.6593542098999023, loss:5.259824275970459
epoch2: step100/160
step 0: accuracy:0.125, confidence:0.6656661033630371, loss:5.2829437255859375
epoch3: step0/160
step 300: accuracy:0.1289999932050705, confidence:0.6737803220748901, loss:5.320923805236816
epoch3: step100/160
step 0: accuracy:0.1469999998807907, confidence:0.6715791821479797, loss:5.236363410949707
epoch4: step0/160
step 400: accuracy:0.12399999797344208, confidence:0.6806638836860657, loss:5.561282634735107
epoch4: step100/160
step 0: accuracy:0.12700000405311584, confidence:0.6896494030952454, loss:5.431513786315918
epoch5: step0/160
step 500: accuracy:0.11500000208616257, confidence:0.6876979470252991, loss:5.433475017547607
epoch5: step100/160
step 0: accuracy:0.13500000536441803, confidence:0.6718629002571106, loss:5.195694446563721
epoch6: step0/160
step 600: accuracy:0.13500000536441803, confidence:0.6825082898139954, loss:5.251660346984863
epoch6: step100/160
step 0: accuracy:0.13099999725818634, confidence:0.6858493685722351, loss:5.594176769256592
epoch7: step0/160
step 700: accuracy:0.13300000131130219, confidence:0.6912227869033813, loss:5.3382887840271
epoch7: step100/160
step 0: accuracy:0.14000000059604645, confidence:0.6782439947128296, loss:5.276554584503174
epoch8: step0/160
step 800: accuracy:0.14000000059604645, confidence:0.6759988069534302, loss:5.414888858795166
epoch8: step100/160
step 0: accuracy:0.1120000034570694, confidence:0.6821704506874084, loss:5.4906086921691895
epoch9: step0/160
step 900: accuracy:0.10499999672174454, confidence:0.6852999329566956, loss:5.415470600128174
epoch9: step100/160
step 0: accuracy:0.11800000071525574, confidence:0.6669033765792847, loss:5.3958048820495605
epoch10: step0/160
step 1000: accuracy:0.12600000202655792, confidence:0.6740434765815735, loss:5.206240177154541
epoch10: step100/160
step 0: accuracy:0.10999999940395355, confidence:0.682245135307312, loss:5.320265293121338
epoch11: step0/160
step 1100: accuracy:0.12700000405311584, confidence:0.6815377473831177, loss:5.30289363861084
epoch11: step100/160
step 0: accuracy:0.12399999797344208, confidence:0.6742663383483887, loss:5.2424116134643555
epoch12: step0/160
step 1200: accuracy:0.12300000339746475, confidence:0.6848724484443665, loss:5.202608108520508
epoch12: step100/160
step 0: accuracy:0.10700000077486038, confidence:0.6736577153205872, loss:5.333386421203613
epoch13: step0/160
step 1300: accuracy:0.12200000137090683, confidence:0.6721513867378235, loss:5.233029842376709
epoch13: step100/160
step 0: accuracy:0.1340000033378601, confidence:0.6620160937309265, loss:5.2341485023498535
epoch14: step0/160
step 1400: accuracy:0.10899999737739563, confidence:0.6775006651878357, loss:5.3770928382873535
epoch14: step100/160
step 0: accuracy:0.1120000034570694, confidence:0.6603339910507202, loss:5.248903751373291
epoch15: step0/160
step 1500: accuracy:0.11500000208616257, confidence:0.6705940961837769, loss:5.170633792877197
epoch15: step100/160
step 0: accuracy:0.10499999672174454, confidence:0.6712136268615723, loss:5.280463695526123
epoch16: step0/160
step 1600: accuracy:0.11400000005960464, confidence:0.6664824485778809, loss:5.198522090911865
epoch16: step100/160
step 0: accuracy:0.1289999932050705, confidence:0.6554216146469116, loss:5.1621809005737305
epoch17: step0/160
step 1700: accuracy:0.11800000071525574, confidence:0.6740387082099915, loss:5.2386932373046875
epoch17: step100/160
step 0: accuracy:0.11800000071525574, confidence:0.6612579822540283, loss:4.982553005218506
epoch18: step0/160
step 1800: accuracy:0.13099999725818634, confidence:0.6681632399559021, loss:5.080813884735107
epoch18: step100/160
step 0: accuracy:0.11100000143051147, confidence:0.6643980741500854, loss:5.136332988739014
epoch19: step0/160
step 1900: accuracy:0.11500000208616257, confidence:0.670860767364502, loss:5.130616664886475
epoch19: step100/160
step 0: accuracy:0.10700000077486038, confidence:0.6472376585006714, loss:5.031521797180176
epoch20: step0/160
step 2000: accuracy:0.13300000131130219, confidence:0.6641584634780884, loss:5.086067199707031
epoch20: step100/160
step 0: accuracy:0.12200000137090683, confidence:0.6521839499473572, loss:4.9363813400268555
epoch21: step0/160
step 2100: accuracy:0.10700000077486038, confidence:0.662810206413269, loss:5.080331325531006
epoch21: step100/160
step 0: accuracy:0.10400000214576721, confidence:0.6527547240257263, loss:4.944755554199219
epoch22: step0/160
step 2200: accuracy:0.11100000143051147, confidence:0.6498919725418091, loss:5.134444236755371
epoch22: step100/160
step 0: accuracy:0.11500000208616257, confidence:0.6427177786827087, loss:4.983058929443359
epoch23: step0/160
step 2300: accuracy:0.11299999803304672, confidence:0.6720480918884277, loss:5.2001729011535645
epoch23: step100/160
step 0: accuracy:0.1080000028014183, confidence:0.6661882400512695, loss:5.286898136138916
epoch24: step0/160
step 2400: accuracy:0.13300000131130219, confidence:0.6928489804267883, loss:5.3928680419921875
epoch24: step100/160
step 0: accuracy:0.0989999994635582, confidence:0.657014012336731, loss:5.347752094268799
epoch25: step0/160
step 2500: accuracy:0.10999999940395355, confidence:0.6740346550941467, loss:5.257106781005859
epoch25: step100/160
step 0: accuracy:0.10599999874830246, confidence:0.6579172015190125, loss:5.183345317840576
epoch26: step0/160
step 2600: accuracy:0.11400000005960464, confidence:0.6626828908920288, loss:5.170261859893799
epoch26: step100/160
step 0: accuracy:0.1080000028014183, confidence:0.6528814435005188, loss:5.145735740661621
epoch27: step0/160
step 2700: accuracy:0.11699999868869781, confidence:0.6654488444328308, loss:5.100276470184326
epoch27: step100/160
step 0: accuracy:0.10700000077486038, confidence:0.6536523103713989, loss:5.149284839630127
epoch28: step0/160
step 2800: accuracy:0.13300000131130219, confidence:0.6600788235664368, loss:5.001306056976318
epoch28: step100/160
step 0: accuracy:0.10700000077486038, confidence:0.6408077478408813, loss:5.085277080535889
epoch29: step0/160
step 2900: accuracy:0.10400000214576721, confidence:0.6664484739303589, loss:5.321506023406982
epoch29: step100/160
step 0: accuracy:0.10499999672174454, confidence:0.6474442481994629, loss:5.088598251342773
epoch30: step0/160
step 3000: accuracy:0.10100000351667404, confidence:0.6914070248603821, loss:5.320157051086426
epoch30: step100/160
step 0: accuracy:0.09399999678134918, confidence:0.6547873616218567, loss:5.209587097167969
epoch31: step0/160
step 3100: accuracy:0.0989999994635582, confidence:0.6665329933166504, loss:5.124965667724609
epoch31: step100/160
step 0: accuracy:0.10100000351667404, confidence:0.6419564485549927, loss:5.066591262817383
epoch32: step0/160
step 3200: accuracy:0.10199999809265137, confidence:0.6604822278022766, loss:5.000242233276367
epoch32: step100/160
step 0: accuracy:0.0989999994635582, confidence:0.653570294380188, loss:5.184751033782959
epoch33: step0/160
step 3300: accuracy:0.125, confidence:0.6878396272659302, loss:4.989291191101074
epoch33: step100/160
step 0: accuracy:0.11400000005960464, confidence:0.6419614553451538, loss:4.927052021026611
epoch34: step0/160
step 3400: accuracy:0.10499999672174454, confidence:0.6618059873580933, loss:5.238761901855469
epoch34: step100/160
step 0: accuracy:0.10899999737739563, confidence:0.6537661552429199, loss:5.038531303405762
epoch35: step0/160
step 3500: accuracy:0.09799999743700027, confidence:0.6656086444854736, loss:5.197048187255859
epoch35: step100/160
step 0: accuracy:0.09000000357627869, confidence:0.652249276638031, loss:5.010291576385498
epoch36: step0/160
step 3600: accuracy:0.11599999666213989, confidence:0.667349100112915, loss:5.10703706741333
epoch36: step100/160
step 0: accuracy:0.0949999988079071, confidence:0.6676396131515503, loss:5.197190284729004
epoch37: step0/160
step 3700: accuracy:0.0949999988079071, confidence:0.6854872107505798, loss:5.284313201904297
epoch37: step100/160
step 0: accuracy:0.10899999737739563, confidence:0.649022102355957, loss:4.959731578826904
epoch38: step0/160
step 3800: accuracy:0.09700000286102295, confidence:0.6746772527694702, loss:5.165807247161865
epoch38: step100/160
step 0: accuracy:0.08799999952316284, confidence:0.6607310771942139, loss:5.22382926940918
epoch39: step0/160
step 3900: accuracy:0.09399999678134918, confidence:0.674532949924469, loss:5.316573619842529
epoch39: step100/160
step 0: accuracy:0.10300000011920929, confidence:0.6604662537574768, loss:5.227717399597168
epoch40: step0/160
step 4000: accuracy:0.0949999988079071, confidence:0.668576180934906, loss:5.446286678314209
epoch40: step100/160
step 0: accuracy:0.0689999982714653, confidence:0.6817028522491455, loss:6.785242080688477
epoch41: step0/160
step 4100: accuracy:0.11299999803304672, confidence:0.6671004295349121, loss:5.4417948722839355
epoch41: step100/160
step 0: accuracy:0.10100000351667404, confidence:0.674403190612793, loss:5.61788272857666
epoch42: step0/160
step 4200: accuracy:0.12800000607967377, confidence:0.6857947707176208, loss:5.606068134307861
epoch42: step100/160
step 0: accuracy:0.11400000005960464, confidence:0.6907783150672913, loss:5.6733622550964355
epoch43: step0/160
step 4300: accuracy:0.1120000034570694, confidence:0.6850676536560059, loss:5.755341053009033
epoch43: step100/160
step 0: accuracy:0.0989999994635582, confidence:0.6937292218208313, loss:5.6499152183532715
epoch44: step0/160
step 4400: accuracy:0.10400000214576721, confidence:0.6990313529968262, loss:5.700050354003906
epoch44: step100/160
step 0: accuracy:0.11400000005960464, confidence:0.6902467012405396, loss:5.580552101135254
epoch45: step0/160
step 4500: accuracy:0.10199999809265137, confidence:0.6960501670837402, loss:5.728121280670166
epoch45: step100/160
step 0: accuracy:0.10300000011920929, confidence:0.6925250291824341, loss:5.669930934906006
epoch46: step0/160
step 4600: accuracy:0.10000000149011612, confidence:0.6880614757537842, loss:5.462058067321777
epoch46: step100/160
step 0: accuracy:0.11999999731779099, confidence:0.6871911883354187, loss:5.455132484436035
epoch47: step0/160
step 4700: accuracy:0.1080000028014183, confidence:0.7039430141448975, loss:5.491497993469238
epoch47: step100/160
step 0: accuracy:0.12099999934434891, confidence:0.7022287845611572, loss:5.364891052246094
epoch48: step0/160
step 4800: accuracy:0.125, confidence:0.7040295600891113, loss:5.479874134063721
epoch48: step100/160
step 0: accuracy:0.11299999803304672, confidence:0.7006931304931641, loss:5.473050594329834
epoch49: step0/160
step 4900: accuracy:0.10199999809265137, confidence:0.7105570435523987, loss:5.541750907897949
epoch49: step100/160
step 0: accuracy:0.11400000005960464, confidence:0.7023943066596985, loss:5.5126495361328125
epoch50: step0/160
step 5000: accuracy:0.11800000071525574, confidence:0.7037415504455566, loss:5.5261712074279785
epoch50: step100/160
step 0: accuracy:0.0949999988079071, confidence:0.6891521215438843, loss:5.496904373168945
epoch51: step0/160
step 5100: accuracy:0.10499999672174454, confidence:0.7003224492073059, loss:5.457289218902588
epoch51: step100/160
step 0: accuracy:0.09399999678134918, confidence:0.6970105171203613, loss:5.627572536468506
epoch52: step0/160
step 5200: accuracy:0.10300000011920929, confidence:0.6994956135749817, loss:5.689053535461426
epoch52: step100/160
step 0: accuracy:0.07800000160932541, confidence:0.6949431300163269, loss:5.696019649505615
epoch53: step0/160
step 5300: accuracy:0.09799999743700027, confidence:0.703961968421936, loss:5.527956962585449
epoch53: step100/160
step 0: accuracy:0.09399999678134918, confidence:0.6965308785438538, loss:5.480997562408447
epoch54: step0/160
step 5400: accuracy:0.1120000034570694, confidence:0.6839389801025391, loss:5.383445739746094
epoch54: step100/160
step 0: accuracy:0.11599999666213989, confidence:0.6907102465629578, loss:5.403014659881592
epoch55: step0/160
step 5500: accuracy:0.10599999874830246, confidence:0.7073635458946228, loss:5.583441734313965
epoch55: step100/160
step 0: accuracy:0.08799999952316284, confidence:0.6788280606269836, loss:5.435593128204346
epoch56: step0/160
step 5600: accuracy:0.1120000034570694, confidence:0.7098091244697571, loss:5.4788031578063965
epoch56: step100/160
step 0: accuracy:0.08500000089406967, confidence:0.6919198036193848, loss:5.690056324005127
epoch57: step0/160
step 5700: accuracy:0.10400000214576721, confidence:0.6854184865951538, loss:5.330878257751465
epoch57: step100/160
step 0: accuracy:0.08799999952316284, confidence:0.6877791285514832, loss:5.581478595733643
epoch58: step0/160
step 5800: accuracy:0.0949999988079071, confidence:0.6918092370033264, loss:5.52349328994751
epoch58: step100/160
step 0: accuracy:0.08699999749660492, confidence:0.6863749027252197, loss:5.565532684326172
epoch59: step0/160
step 5900: accuracy:0.09099999815225601, confidence:0.6959672570228577, loss:5.525184631347656
epoch59: step100/160
step 0: accuracy:0.10700000077486038, confidence:0.6852809190750122, loss:5.533039569854736
epoch60: step0/160
step 6000: accuracy:0.10599999874830246, confidence:0.6967297792434692, loss:5.610806941986084
epoch60: step100/160
step 0: accuracy:0.0860000029206276, confidence:0.6748176217079163, loss:5.765315532684326
epoch61: step0/160
step 6100: accuracy:0.09300000220537186, confidence:0.7053050994873047, loss:5.6730146408081055
epoch61: step100/160
step 0: accuracy:0.09799999743700027, confidence:0.6837610602378845, loss:5.612756729125977
epoch62: step0/160
step 6200: accuracy:0.08500000089406967, confidence:0.6929174065589905, loss:5.640290260314941
epoch62: step100/160
step 0: accuracy:0.08799999952316284, confidence:0.686138927936554, loss:5.471081256866455
epoch63: step0/160
step 6300: accuracy:0.0989999994635582, confidence:0.6925374865531921, loss:5.709383964538574
epoch63: step100/160
step 0: accuracy:0.09300000220537186, confidence:0.6861901879310608, loss:5.701934337615967
epoch64: step0/160
step 6400: accuracy:0.08299999684095383, confidence:0.7124516367912292, loss:5.874038219451904
epoch64: step100/160
step 0: accuracy:0.09799999743700027, confidence:0.6812995672225952, loss:5.529290199279785
epoch65: step0/160
step 6500: accuracy:0.10599999874830246, confidence:0.6956466436386108, loss:5.605079650878906
epoch65: step100/160
step 0: accuracy:0.10499999672174454, confidence:0.6840556263923645, loss:5.5670294761657715
epoch66: step0/160
step 6600: accuracy:0.09600000083446503, confidence:0.702645480632782, loss:5.6742472648620605
epoch66: step100/160
step 0: accuracy:0.08500000089406967, confidence:0.6842408180236816, loss:5.810609817504883
epoch67: step0/160
step 6700: accuracy:0.10599999874830246, confidence:0.7023364305496216, loss:5.602004051208496
epoch67: step100/160
step 0: accuracy:0.08399999886751175, confidence:0.6964935660362244, loss:5.828563213348389
epoch68: step0/160
step 6800: accuracy:0.10599999874830246, confidence:0.7052006721496582, loss:5.798172950744629
epoch68: step100/160
step 0: accuracy:0.10100000351667404, confidence:0.6828916072845459, loss:5.782899856567383
epoch69: step0/160
step 6900: accuracy:0.10000000149011612, confidence:0.708592414855957, loss:5.829731464385986
epoch69: step100/160
step 0: accuracy:0.0949999988079071, confidence:0.6997548341751099, loss:5.980396747589111
epoch70: step0/160
step 7000: accuracy:0.09799999743700027, confidence:0.7003198862075806, loss:5.869614601135254
epoch70: step100/160
step 0: accuracy:0.10100000351667404, confidence:0.7098128795623779, loss:5.824128150939941
epoch71: step0/160
step 7100: accuracy:0.10000000149011612, confidence:0.6401696801185608, loss:5.634312629699707
epoch71: step100/160
step 0: accuracy:0.11800000071525574, confidence:0.6561440229415894, loss:5.862788200378418
epoch72: step0/160
step 7200: accuracy:0.11500000208616257, confidence:0.6789852976799011, loss:5.864699840545654
epoch72: step100/160
step 0: accuracy:0.10300000011920929, confidence:0.6810951828956604, loss:6.002050876617432
epoch73: step0/160
step 7300: accuracy:0.10700000077486038, confidence:0.6898197531700134, loss:5.807144641876221
epoch73: step100/160
step 0: accuracy:0.1120000034570694, confidence:0.7014275789260864, loss:5.828965187072754
epoch74: step0/160
step 7400: accuracy:0.11699999868869781, confidence:0.703433096408844, loss:5.754505634307861
epoch74: step100/160
step 0: accuracy:0.12700000405311584, confidence:0.6959257125854492, loss:5.586789131164551
epoch75: step0/160
step 7500: accuracy:0.10199999809265137, confidence:0.7062337398529053, loss:5.742474555969238
epoch75: step100/160
step 0: accuracy:0.09300000220537186, confidence:0.7120595574378967, loss:6.122734546661377
epoch76: step0/160
step 7600: accuracy:0.1080000028014183, confidence:0.7064312696456909, loss:5.923858165740967
epoch76: step100/160
step 0: accuracy:0.10499999672174454, confidence:0.719229519367218, loss:6.061448097229004
epoch77: step0/160
step 7700: accuracy:0.10499999672174454, confidence:0.7197391986846924, loss:6.024343967437744
epoch77: step100/160
step 0: accuracy:0.10000000149011612, confidence:0.7035931944847107, loss:5.818083763122559
epoch78: step0/160
step 7800: accuracy:0.10599999874830246, confidence:0.6901835203170776, loss:5.665857315063477
epoch78: step100/160
step 0: accuracy:0.11299999803304672, confidence:0.696947455406189, loss:5.682430744171143
epoch79: step0/160
step 7900: accuracy:0.12200000137090683, confidence:0.7082345485687256, loss:5.755111217498779
epoch79: step100/160
step 0: accuracy:0.11100000143051147, confidence:0.6896430253982544, loss:5.703500747680664
epoch80: step0/160
step 8000: accuracy:0.09799999743700027, confidence:0.7089940309524536, loss:6.022936820983887
epoch80: step100/160
step 0: accuracy:0.11100000143051147, confidence:0.7078755497932434, loss:5.816252708435059
epoch81: step0/160
step 8100: accuracy:0.1080000028014183, confidence:0.6982336640357971, loss:5.8253326416015625
epoch81: step100/160
step 0: accuracy:0.0989999994635582, confidence:0.6949220299720764, loss:5.798303127288818
epoch82: step0/160
step 8200: accuracy:0.09099999815225601, confidence:0.6892032623291016, loss:5.675833702087402
epoch82: step100/160
step 0: accuracy:0.08100000023841858, confidence:0.6979860067367554, loss:6.116187572479248
epoch83: step0/160
step 8300: accuracy:0.10100000351667404, confidence:0.701303243637085, loss:5.735296249389648
epoch83: step100/160
step 0: accuracy:0.10499999672174454, confidence:0.7102853059768677, loss:5.990352153778076
epoch84: step0/160
step 8400: accuracy:0.10300000011920929, confidence:0.7133301496505737, loss:5.798222541809082
epoch84: step100/160
step 0: accuracy:0.09099999815225601, confidence:0.6910492181777954, loss:6.00244665145874
epoch85: step0/160
step 8500: accuracy:0.10999999940395355, confidence:0.6987333297729492, loss:5.831746578216553
epoch85: step100/160
step 0: accuracy:0.09600000083446503, confidence:0.706674337387085, loss:6.056910991668701
epoch86: step0/160
step 8600: accuracy:0.1080000028014183, confidence:0.7118815779685974, loss:5.952035427093506
epoch86: step100/160
step 0: accuracy:0.10499999672174454, confidence:0.694496214389801, loss:5.785233020782471
epoch87: step0/160
step 8700: accuracy:0.08500000089406967, confidence:0.713199257850647, loss:5.997223377227783
epoch87: step100/160
step 0: accuracy:0.10400000214576721, confidence:0.697121798992157, loss:5.949921607971191
epoch88: step0/160
step 8800: accuracy:0.07900000363588333, confidence:0.7189723253250122, loss:6.081629276275635
epoch88: step100/160
step 0: accuracy:0.11699999868869781, confidence:0.6956424117088318, loss:5.851266384124756
epoch89: step0/160
step 8900: accuracy:0.08900000154972076, confidence:0.6934356689453125, loss:5.915318965911865
epoch89: step100/160
step 0: accuracy:0.10100000351667404, confidence:0.7055178284645081, loss:6.0786590576171875
epoch90: step0/160
step 9000: accuracy:0.10000000149011612, confidence:0.7073772549629211, loss:6.06445837020874
epoch90: step100/160
step 0: accuracy:0.09300000220537186, confidence:0.7034415006637573, loss:5.911623477935791
epoch91: step0/160
step 9100: accuracy:0.0949999988079071, confidence:0.7065521478652954, loss:6.04522180557251
epoch91: step100/160
step 0: accuracy:0.08699999749660492, confidence:0.6981667876243591, loss:6.028653621673584
epoch92: step0/160
step 9200: accuracy:0.10700000077486038, confidence:0.6996031999588013, loss:5.839479923248291
epoch92: step100/160
step 0: accuracy:0.10000000149011612, confidence:0.6949347257614136, loss:6.062257766723633
epoch93: step0/160
step 9300: accuracy:0.09700000286102295, confidence:0.7035301923751831, loss:5.957499980926514
epoch93: step100/160
step 0: accuracy:0.09600000083446503, confidence:0.7028390169143677, loss:5.93302059173584
epoch94: step0/160
step 9400: accuracy:0.09300000220537186, confidence:0.7029775381088257, loss:5.840768814086914
epoch94: step100/160
step 0: accuracy:0.09600000083446503, confidence:0.6979022026062012, loss:6.113993167877197
epoch95: step0/160
step 9500: accuracy:0.07800000160932541, confidence:0.7090715169906616, loss:5.952749729156494
epoch95: step100/160
step 0: accuracy:0.0989999994635582, confidence:0.6967917680740356, loss:5.967590808868408
epoch96: step0/160
step 9600: accuracy:0.0949999988079071, confidence:0.7245082259178162, loss:5.963271617889404
epoch96: step100/160
step 0: accuracy:0.09600000083446503, confidence:0.6881598830223083, loss:6.067615509033203
epoch97: step0/160
step 9700: accuracy:0.08500000089406967, confidence:0.7233244776725769, loss:6.306814670562744
epoch97: step100/160
step 0: accuracy:0.08500000089406967, confidence:0.6965727210044861, loss:6.191465854644775
epoch98: step0/160
step 9800: accuracy:0.0860000029206276, confidence:0.7021437883377075, loss:5.974354267120361
epoch98: step100/160
step 0: accuracy:0.09099999815225601, confidence:0.697817325592041, loss:6.04238224029541
epoch99: step0/160
step 9900: accuracy:0.08900000154972076, confidence:0.7093115448951721, loss:6.000972747802734
epoch99: step100/160
