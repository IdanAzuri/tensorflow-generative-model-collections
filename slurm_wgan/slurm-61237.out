2018-06-04 16:33:11.935751: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1105] Found device 0 with properties: 
name: Tesla P100-SXM2-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.4805
pciBusID: 0002:01:00.0
totalMemory: 15.90GiB freeMemory: 15.61GiB
2018-06-04 16:33:11.945748: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1195] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla P100-SXM2-16GB, pci bus id: 0002:01:00.0, compute capability: 6.0)
2018-06-04 16:33:20.337642: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1195] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla P100-SXM2-16GB, pci bus id: 0002:01:00.0, compute capability: 6.0)
/usr/lib/python3/dist-packages/numpy/core/machar.py:127: RuntimeWarning: overflow encountered in add
  a = a + a
/usr/lib/python3/dist-packages/numpy/core/machar.py:129: RuntimeWarning: invalid value encountered in subtract
  temp1 = temp - a
/usr/lib/python3/dist-packages/numpy/core/machar.py:138: RuntimeWarning: invalid value encountered in subtract
  itemp = int_conv(temp-a)
/usr/lib/python3/dist-packages/numpy/core/machar.py:162: RuntimeWarning: overflow encountered in add
  a = a + a
/usr/lib/python3/dist-packages/numpy/core/machar.py:164: RuntimeWarning: invalid value encountered in subtract
  temp1 = temp - a
/usr/lib/python3/dist-packages/numpy/core/machar.py:171: RuntimeWarning: invalid value encountered in subtract
  if any(temp-a != zero):
model has been loaded from fashion-mnist_classifier.pkl
Saving graph to: logs/fashion-mnist/train
---------
Variables: name (type shape) [size]
---------
Variable:0 (float32_ref 5x5x1x32) [800, bytes: 3200]
Variable_1:0 (float32_ref 32) [32, bytes: 128]
Variable_2:0 (float32_ref 5x5x32x64) [51200, bytes: 204800]
Variable_3:0 (float32_ref 64) [64, bytes: 256]
Variable_4:0 (float32_ref 3136x1024) [3211264, bytes: 12845056]
Variable_5:0 (float32_ref 1024) [1024, bytes: 4096]
Variable_6:0 (float32_ref 1024x10) [10240, bytes: 40960]
Variable_7:0 (float32_ref 10) [10, bytes: 40]
discriminator/d_conv1/w:0 (float32_ref 4x4x1x64) [1024, bytes: 4096]
discriminator/d_conv1/biases:0 (float32_ref 64) [64, bytes: 256]
discriminator/d_conv2/w:0 (float32_ref 4x4x64x128) [131072, bytes: 524288]
discriminator/d_conv2/biases:0 (float32_ref 128) [128, bytes: 512]
discriminator/d_bn2/beta:0 (float32_ref 128) [128, bytes: 512]
discriminator/d_bn2/gamma:0 (float32_ref 128) [128, bytes: 512]
discriminator/d_fc3/Matrix:0 (float32_ref 6272x1024) [6422528, bytes: 25690112]
discriminator/d_fc3/bias:0 (float32_ref 1024) [1024, bytes: 4096]
discriminator/d_bn3/beta:0 (float32_ref 1024) [1024, bytes: 4096]
discriminator/d_bn3/gamma:0 (float32_ref 1024) [1024, bytes: 4096]
discriminator/d_fc4/Matrix:0 (float32_ref 1024x1) [1024, bytes: 4096]
discriminator/d_fc4/bias:0 (float32_ref 1) [1, bytes: 4]
generator/g_fc1/Matrix:0 (float32_ref 74x1024) [75776, bytes: 303104]
generator/g_fc1/bias:0 (float32_ref 1024) [1024, bytes: 4096]
generator/g_bn1/beta:0 (float32_ref 1024) [1024, bytes: 4096]
generator/g_bn1/gamma:0 (float32_ref 1024) [1024, bytes: 4096]
generator/g_fc2/Matrix:0 (float32_ref 1024x6272) [6422528, bytes: 25690112]
generator/g_fc2/bias:0 (float32_ref 6272) [6272, bytes: 25088]
generator/g_bn2/beta:0 (float32_ref 6272) [6272, bytes: 25088]
generator/g_bn2/gamma:0 (float32_ref 6272) [6272, bytes: 25088]
generator/g_dc3/w:0 (float32_ref 4x4x64x128) [131072, bytes: 524288]
generator/g_dc3/biases:0 (float32_ref 64) [64, bytes: 256]
generator/g_bn3/beta:0 (float32_ref 64) [64, bytes: 256]
generator/g_bn3/gamma:0 (float32_ref 64) [64, bytes: 256]
generator/g_dc4/w:0 (float32_ref 4x4x1x64) [1024, bytes: 4096]
generator/g_dc4/biases:0 (float32_ref 1) [1, bytes: 4]
classifier/c_fc1/Matrix:0 (float32_ref 1024x64) [65536, bytes: 262144]
classifier/c_fc1/bias:0 (float32_ref 64) [64, bytes: 256]
classifier/c_bn1/beta:0 (float32_ref 64) [64, bytes: 256]
classifier/c_bn1/gamma:0 (float32_ref 64) [64, bytes: 256]
classifier/c_fc2/Matrix:0 (float32_ref 64x12) [768, bytes: 3072]
classifier/c_fc2/bias:0 (float32_ref 12) [12, bytes: 48]
Total size of variables: 16552792
Total bytes of variables: 66211168
 [*] Reading checkpoints...
 [*] Success to read MultiModalInfoGAN.model-43721
 [*] Load SUCCESS
 [*] Training finished!
step 39: accuracy:0.171875, confidence:0.9426484704017639, loss:110.33259582519531
 [*] Testing finished!
2018-06-04 16:34:53.388482: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1105] Found device 0 with properties: 
name: Tesla P100-SXM2-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.4805
pciBusID: 0002:01:00.0
totalMemory: 15.90GiB freeMemory: 15.61GiB
2018-06-04 16:34:54.390594: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1195] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla P100-SXM2-16GB, pci bus id: 0002:01:00.0, compute capability: 6.0)
/usr/lib/python3/dist-packages/numpy/core/machar.py:127: RuntimeWarning: overflow encountered in add
  a = a + a
/usr/lib/python3/dist-packages/numpy/core/machar.py:129: RuntimeWarning: invalid value encountered in subtract
  temp1 = temp - a
/usr/lib/python3/dist-packages/numpy/core/machar.py:138: RuntimeWarning: invalid value encountered in subtract
  itemp = int_conv(temp-a)
/usr/lib/python3/dist-packages/numpy/core/machar.py:162: RuntimeWarning: overflow encountered in add
  a = a + a
/usr/lib/python3/dist-packages/numpy/core/machar.py:164: RuntimeWarning: invalid value encountered in subtract
  temp1 = temp - a
/usr/lib/python3/dist-packages/numpy/core/machar.py:171: RuntimeWarning: invalid value encountered in subtract
  if any(temp-a != zero):
model has been loaded from mnist_classifier.pkl
Saving graph to: logs/mnist/train
argmax:[8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8
 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]
step 0: accuracy:0.10000000149011612, confidence:0.7278668880462646, loss:4.651435852050781
[ 0  0  0  0  0  0  0  0 60]
argmax:[8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8
 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]
step 0: accuracy:0.10000000149011612, confidence:0.7324355840682983, loss:4.638734817504883
[ 0  0  0  0  0  0  0  0 60]
argmax:[8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8
 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]
step 0: accuracy:0.10000000149011612, confidence:0.4315604567527771, loss:3.133145332336426
[ 0  0  0  0  0  0  0  0 60]
argmax:[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]
step 0: accuracy:0.10000000149011612, confidence:0.9870474338531494, loss:7.7788615226745605
[ 0  0 60]
argmax:[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]
step 0: accuracy:0.10000000149011612, confidence:0.957016110420227, loss:5.8473358154296875
[ 0  0 60]
argmax:[8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8
 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]
step 0: accuracy:0.10000000149011612, confidence:0.9285768866539001, loss:4.903843402862549
[ 0  0  0  0  0  0  0  0 60]
argmax:[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]
step 0: accuracy:0.10000000149011612, confidence:0.498212993144989, loss:3.9045751094818115
[60]
argmax:[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]
step 0: accuracy:0.10000000149011612, confidence:0.922055184841156, loss:5.276383399963379
[ 0  0 60]
argmax:[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
step 0: accuracy:0.10000000149011612, confidence:0.2710152864456177, loss:3.671954870223999
[ 0 60]
argmax:[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]
step 0: accuracy:0.10000000149011612, confidence:0.5485985279083252, loss:4.086662769317627
[60]
2018-06-04 16:35:11.227284: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1105] Found device 0 with properties: 
name: Tesla P100-SXM2-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.4805
pciBusID: 0002:01:00.0
totalMemory: 15.90GiB freeMemory: 15.61GiB
2018-06-04 16:35:11.404229: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1195] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla P100-SXM2-16GB, pci bus id: 0002:01:00.0, compute capability: 6.0)
/usr/lib/python3/dist-packages/numpy/core/machar.py:127: RuntimeWarning: overflow encountered in add
  a = a + a
/usr/lib/python3/dist-packages/numpy/core/machar.py:129: RuntimeWarning: invalid value encountered in subtract
  temp1 = temp - a
/usr/lib/python3/dist-packages/numpy/core/machar.py:138: RuntimeWarning: invalid value encountered in subtract
  itemp = int_conv(temp-a)
/usr/lib/python3/dist-packages/numpy/core/machar.py:162: RuntimeWarning: overflow encountered in add
  a = a + a
/usr/lib/python3/dist-packages/numpy/core/machar.py:164: RuntimeWarning: invalid value encountered in subtract
  temp1 = temp - a
/usr/lib/python3/dist-packages/numpy/core/machar.py:171: RuntimeWarning: invalid value encountered in subtract
  if any(temp-a != zero):
Saving graph to: logs/fashion-mnist_UniformSample_train
step 0: accuracy:0.07500000298023224, confidence:0.5317001938819885, loss:4.283634662628174
epoch0: step0/160
step 0: accuracy:0.09600000083446503, confidence:0.7242975831031799, loss:9.801547050476074
epoch0: step100/160
step 0: accuracy:0.12300000339746475, confidence:0.7406073808670044, loss:9.917534828186035
epoch1: step0/160
step 100: accuracy:0.10999999940395355, confidence:0.7637116312980652, loss:9.6912841796875
epoch1: step100/160
step 0: accuracy:0.09600000083446503, confidence:0.7691926956176758, loss:9.634542465209961
epoch2: step0/160
step 200: accuracy:0.11999999731779099, confidence:0.7977685332298279, loss:9.608732223510742
epoch2: step100/160
step 0: accuracy:0.1120000034570694, confidence:0.7792896032333374, loss:9.750718116760254
epoch3: step0/160
step 300: accuracy:0.10599999874830246, confidence:0.787580668926239, loss:9.949007034301758
epoch3: step100/160
step 0: accuracy:0.13099999725818634, confidence:0.7796230316162109, loss:9.11925983428955
epoch4: step0/160
step 400: accuracy:0.10999999940395355, confidence:0.7915602326393127, loss:9.644451141357422
epoch4: step100/160
step 0: accuracy:0.12700000405311584, confidence:0.7961366176605225, loss:9.408246040344238
epoch5: step0/160
step 500: accuracy:0.11999999731779099, confidence:0.8092440962791443, loss:9.519546508789062
epoch5: step100/160
step 0: accuracy:0.11699999868869781, confidence:0.7845579981803894, loss:9.391647338867188
epoch6: step0/160
step 600: accuracy:0.1289999932050705, confidence:0.8175328969955444, loss:9.239751815795898
epoch6: step100/160
step 0: accuracy:0.1469999998807907, confidence:0.8162441253662109, loss:8.563962936401367
epoch7: step0/160
step 700: accuracy:0.11400000005960464, confidence:0.8033908605575562, loss:9.128689765930176
epoch7: step100/160
step 0: accuracy:0.11400000005960464, confidence:0.8120962977409363, loss:8.827744483947754
epoch8: step0/160
step 800: accuracy:0.11999999731779099, confidence:0.8205035328865051, loss:9.399725914001465
epoch8: step100/160
step 0: accuracy:0.12099999934434891, confidence:0.7913581728935242, loss:8.990447044372559
epoch9: step0/160
step 900: accuracy:0.1080000028014183, confidence:0.8088604807853699, loss:9.218679428100586
epoch9: step100/160
step 0: accuracy:0.12300000339746475, confidence:0.7974887490272522, loss:8.857081413269043
epoch10: step0/160
step 1000: accuracy:0.13300000131130219, confidence:0.8125832080841064, loss:8.96834945678711
epoch10: step100/160
step 0: accuracy:0.13699999451637268, confidence:0.7916650176048279, loss:8.705095291137695
epoch11: step0/160
step 1100: accuracy:0.14300000667572021, confidence:0.823965311050415, loss:8.4971284866333
epoch11: step100/160
step 0: accuracy:0.12999999523162842, confidence:0.7684597969055176, loss:8.353745460510254
epoch12: step0/160
step 1200: accuracy:0.1379999965429306, confidence:0.805378258228302, loss:8.21338176727295
epoch12: step100/160
step 0: accuracy:0.16099999845027924, confidence:0.8113065958023071, loss:8.11731243133545
epoch13: step0/160
step 1300: accuracy:0.1340000033378601, confidence:0.8328059911727905, loss:8.483749389648438
epoch13: step100/160
step 0: accuracy:0.125, confidence:0.8040270209312439, loss:8.153036117553711
epoch14: step0/160
step 1400: accuracy:0.12099999934434891, confidence:0.8291411399841309, loss:8.723509788513184
epoch14: step100/160
step 0: accuracy:0.1469999998807907, confidence:0.8219195008277893, loss:8.188039779663086
epoch15: step0/160
step 1500: accuracy:0.1340000033378601, confidence:0.8199238181114197, loss:8.128507614135742
epoch15: step100/160
step 0: accuracy:0.1340000033378601, confidence:0.8080312609672546, loss:8.509981155395508
epoch16: step0/160
step 1600: accuracy:0.11999999731779099, confidence:0.8158224821090698, loss:8.282569885253906
epoch16: step100/160
step 0: accuracy:0.13699999451637268, confidence:0.8328647017478943, loss:8.415054321289062
epoch17: step0/160
step 1700: accuracy:0.11699999868869781, confidence:0.8300701975822449, loss:8.261433601379395
epoch17: step100/160
step 0: accuracy:0.13099999725818634, confidence:0.8277024030685425, loss:8.488444328308105
epoch18: step0/160
step 1800: accuracy:0.12999999523162842, confidence:0.8159516453742981, loss:8.229534149169922
epoch18: step100/160
step 0: accuracy:0.13199999928474426, confidence:0.8031688332557678, loss:7.872767448425293
epoch19: step0/160
step 1900: accuracy:0.12999999523162842, confidence:0.8515843152999878, loss:8.427265167236328
epoch19: step100/160
step 0: accuracy:0.11999999731779099, confidence:0.8353180885314941, loss:8.451324462890625
epoch20: step0/160
step 2000: accuracy:0.12700000405311584, confidence:0.8398058414459229, loss:7.879740238189697
epoch20: step100/160
step 0: accuracy:0.15800000727176666, confidence:0.8347901701927185, loss:7.88467264175415
epoch21: step0/160
step 2100: accuracy:0.1289999932050705, confidence:0.8305275440216064, loss:8.10788345336914
epoch21: step100/160
step 0: accuracy:0.11800000071525574, confidence:0.8265493512153625, loss:7.9412994384765625
epoch22: step0/160
step 2200: accuracy:0.11500000208616257, confidence:0.8328858613967896, loss:7.76789665222168
epoch22: step100/160
step 0: accuracy:0.14300000667572021, confidence:0.8283066153526306, loss:7.831640243530273
epoch23: step0/160
step 2300: accuracy:0.12399999797344208, confidence:0.8401516675949097, loss:8.243515014648438
epoch23: step100/160
step 0: accuracy:0.1289999932050705, confidence:0.8446870446205139, loss:8.216291427612305
epoch24: step0/160
step 2400: accuracy:0.12600000202655792, confidence:0.8424162268638611, loss:7.883749485015869
epoch24: step100/160
step 0: accuracy:0.1289999932050705, confidence:0.8317880630493164, loss:7.792553901672363
epoch25: step0/160
step 2500: accuracy:0.14399999380111694, confidence:0.8429208993911743, loss:7.907435894012451
epoch25: step100/160
step 0: accuracy:0.13699999451637268, confidence:0.8895638585090637, loss:8.91378116607666
epoch26: step0/160
step 2600: accuracy:0.125, confidence:0.8435267210006714, loss:7.4992804527282715
epoch26: step100/160
step 0: accuracy:0.1340000033378601, confidence:0.8483205437660217, loss:7.401546955108643
epoch27: step0/160
step 2700: accuracy:0.13300000131130219, confidence:0.8440848588943481, loss:7.4778056144714355
epoch27: step100/160
step 0: accuracy:0.13500000536441803, confidence:0.8426015377044678, loss:7.638679504394531
epoch28: step0/160
step 2800: accuracy:0.1340000033378601, confidence:0.8491036891937256, loss:7.565025806427002
epoch28: step100/160
step 0: accuracy:0.12600000202655792, confidence:0.8437436819076538, loss:7.871688365936279
epoch29: step0/160
step 2900: accuracy:0.12600000202655792, confidence:0.8403617143630981, loss:7.871052265167236
epoch29: step100/160
step 0: accuracy:0.12600000202655792, confidence:0.8434495329856873, loss:7.909796237945557
epoch30: step0/160
step 3000: accuracy:0.13600000739097595, confidence:0.8517574667930603, loss:7.732273101806641
epoch30: step100/160
step 0: accuracy:0.11800000071525574, confidence:0.8328649401664734, loss:7.837704658508301
epoch31: step0/160
step 3100: accuracy:0.12099999934434891, confidence:0.8416873216629028, loss:7.961001873016357
epoch31: step100/160
step 0: accuracy:0.14000000059604645, confidence:0.8335056304931641, loss:7.661954402923584
epoch32: step0/160
step 3200: accuracy:0.13600000739097595, confidence:0.832801878452301, loss:7.686588764190674
epoch32: step100/160
step 0: accuracy:0.1340000033378601, confidence:0.8428104519844055, loss:7.646877288818359
epoch33: step0/160
step 3300: accuracy:0.14499999582767487, confidence:0.8469448685646057, loss:7.760130405426025
epoch33: step100/160
step 0: accuracy:0.1379999965429306, confidence:0.8409218192100525, loss:7.715868949890137
epoch34: step0/160
step 3400: accuracy:0.11299999803304672, confidence:0.8521332740783691, loss:7.966710090637207
epoch34: step100/160
step 0: accuracy:0.13600000739097595, confidence:0.8447063565254211, loss:7.857866287231445
epoch35: step0/160
step 3500: accuracy:0.11900000274181366, confidence:0.8471378087997437, loss:8.033323287963867
epoch35: step100/160
step 0: accuracy:0.1379999965429306, confidence:0.8394282460212708, loss:7.660670757293701
epoch36: step0/160
step 3600: accuracy:0.13899999856948853, confidence:0.8445219993591309, loss:7.853157997131348
epoch36: step100/160
step 0: accuracy:0.15700000524520874, confidence:0.8418803811073303, loss:7.621365547180176
epoch37: step0/160
step 3700: accuracy:0.14800000190734863, confidence:0.8689095973968506, loss:7.7104268074035645
epoch37: step100/160
step 0: accuracy:0.13899999856948853, confidence:0.8444686532020569, loss:7.7443742752075195
epoch38: step0/160
step 3800: accuracy:0.11400000005960464, confidence:0.8502687811851501, loss:8.20083999633789
epoch38: step100/160
step 0: accuracy:0.13199999928474426, confidence:0.8470867872238159, loss:7.7728776931762695
epoch39: step0/160
step 3900: accuracy:0.14300000667572021, confidence:0.8574437499046326, loss:7.795127868652344
epoch39: step100/160
step 0: accuracy:0.13699999451637268, confidence:0.8518158793449402, loss:7.755166530609131
epoch40: step0/160
step 4000: accuracy:0.13300000131130219, confidence:0.8588113784790039, loss:8.025020599365234
epoch40: step100/160
step 0: accuracy:0.13099999725818634, confidence:0.8576600551605225, loss:8.037736892700195
epoch41: step0/160
step 4100: accuracy:0.13600000739097595, confidence:0.8685184121131897, loss:8.076363563537598
epoch41: step100/160
step 0: accuracy:0.14000000059604645, confidence:0.8675633072853088, loss:8.017630577087402
epoch42: step0/160
step 4200: accuracy:0.13199999928474426, confidence:0.8651129007339478, loss:7.902700424194336
epoch42: step100/160
step 0: accuracy:0.12999999523162842, confidence:0.840079128742218, loss:7.462995529174805
epoch43: step0/160
step 4300: accuracy:0.14100000262260437, confidence:0.8671496510505676, loss:7.9105963706970215
epoch43: step100/160
step 0: accuracy:0.1469999998807907, confidence:0.8480291366577148, loss:7.796838760375977
epoch44: step0/160
step 4400: accuracy:0.13099999725818634, confidence:0.8778269290924072, loss:8.262086868286133
epoch44: step100/160
step 0: accuracy:0.1420000046491623, confidence:0.8856191635131836, loss:8.388589859008789
epoch45: step0/160
step 4500: accuracy:0.1340000033378601, confidence:0.882794976234436, loss:8.48987102508545
epoch45: step100/160
step 0: accuracy:0.13099999725818634, confidence:0.8597872257232666, loss:7.9847259521484375
epoch46: step0/160
step 4600: accuracy:0.12999999523162842, confidence:0.8643757104873657, loss:7.784490585327148
epoch46: step100/160
step 0: accuracy:0.13899999856948853, confidence:0.8772534132003784, loss:8.175623893737793
epoch47: step0/160
step 4700: accuracy:0.15399999916553497, confidence:0.8650253415107727, loss:7.981947422027588
epoch47: step100/160
step 0: accuracy:0.15600000321865082, confidence:0.8762902021408081, loss:8.171409606933594
epoch48: step0/160
step 4800: accuracy:0.16300000250339508, confidence:0.8837513327598572, loss:8.135102272033691
epoch48: step100/160
step 0: accuracy:0.15000000596046448, confidence:0.8895311951637268, loss:8.708617210388184
epoch49: step0/160
step 4900: accuracy:0.12600000202655792, confidence:0.8922178745269775, loss:8.667447090148926
epoch49: step100/160
step 0: accuracy:0.14300000667572021, confidence:0.9337624907493591, loss:10.260621070861816
epoch50: step0/160
step 5000: accuracy:0.14000000059604645, confidence:0.8669407963752747, loss:7.508981227874756
epoch50: step100/160
step 0: accuracy:0.11699999868869781, confidence:0.8554233312606812, loss:7.487730979919434
epoch51: step0/160
step 5100: accuracy:0.14900000393390656, confidence:0.8723779916763306, loss:7.466719150543213
epoch51: step100/160
step 0: accuracy:0.11500000208616257, confidence:0.8642096519470215, loss:7.845318794250488
epoch52: step0/160
step 5200: accuracy:0.13099999725818634, confidence:0.8837173581123352, loss:7.900869369506836
epoch52: step100/160
step 0: accuracy:0.11299999803304672, confidence:0.871590256690979, loss:7.9524688720703125
epoch53: step0/160
step 5300: accuracy:0.13500000536441803, confidence:0.8725230693817139, loss:7.975709915161133
epoch53: step100/160
step 0: accuracy:0.13699999451637268, confidence:0.859734296798706, loss:7.698835849761963
epoch54: step0/160
step 5400: accuracy:0.1340000033378601, confidence:0.8726789951324463, loss:7.96109676361084
epoch54: step100/160
step 0: accuracy:0.14000000059604645, confidence:0.8704277276992798, loss:7.7495832443237305
epoch55: step0/160
step 5500: accuracy:0.11699999868869781, confidence:0.8753865957260132, loss:8.036438941955566
epoch55: step100/160
step 0: accuracy:0.12300000339746475, confidence:0.8755950927734375, loss:8.169520378112793
epoch56: step0/160
step 5600: accuracy:0.1340000033378601, confidence:0.8780422210693359, loss:8.114912986755371
epoch56: step100/160
step 0: accuracy:0.12200000137090683, confidence:0.8678037524223328, loss:8.17153263092041
epoch57: step0/160
step 5700: accuracy:0.1459999978542328, confidence:0.88209468126297, loss:7.946743965148926
epoch57: step100/160
step 0: accuracy:0.11999999731779099, confidence:0.8720345497131348, loss:8.065916061401367
epoch58: step0/160
step 5800: accuracy:0.13699999451637268, confidence:0.8730858564376831, loss:8.154982566833496
epoch58: step100/160
step 0: accuracy:0.12600000202655792, confidence:0.8715428709983826, loss:8.05809211730957
epoch59: step0/160
step 5900: accuracy:0.13099999725818634, confidence:0.8761242628097534, loss:8.200604438781738
epoch59: step100/160
step 0: accuracy:0.1469999998807907, confidence:0.8674910068511963, loss:7.802595138549805
epoch60: step0/160
step 6000: accuracy:0.13899999856948853, confidence:0.8744423985481262, loss:8.225695610046387
epoch60: step100/160
step 0: accuracy:0.11500000208616257, confidence:0.8589515089988708, loss:8.10152530670166
epoch61: step0/160
step 6100: accuracy:0.13500000536441803, confidence:0.8833171725273132, loss:8.295234680175781
epoch61: step100/160
step 0: accuracy:0.13899999856948853, confidence:0.8683274388313293, loss:8.165209770202637
epoch62: step0/160
step 6200: accuracy:0.12700000405311584, confidence:0.8869755268096924, loss:8.596566200256348
epoch62: step100/160
step 0: accuracy:0.13600000739097595, confidence:0.8676323294639587, loss:8.115915298461914
epoch63: step0/160
step 6300: accuracy:0.14100000262260437, confidence:0.8780842423439026, loss:8.338007926940918
epoch63: step100/160
step 0: accuracy:0.14900000393390656, confidence:0.8685657382011414, loss:7.969067096710205
epoch64: step0/160
step 6400: accuracy:0.10599999874830246, confidence:0.8700084090232849, loss:8.636348724365234
epoch64: step100/160
step 0: accuracy:0.14100000262260437, confidence:0.8628677725791931, loss:8.017437934875488
epoch65: step0/160
step 6500: accuracy:0.14499999582767487, confidence:0.8895039558410645, loss:8.490036964416504
epoch65: step100/160
step 0: accuracy:0.13099999725818634, confidence:0.878268837928772, loss:8.372981071472168
epoch66: step0/160
step 6600: accuracy:0.12200000137090683, confidence:0.8746653199195862, loss:8.361104965209961
epoch66: step100/160
step 0: accuracy:0.1420000046491623, confidence:0.8741546273231506, loss:8.126482963562012
epoch67: step0/160
step 6700: accuracy:0.13300000131130219, confidence:0.8639211654663086, loss:8.192777633666992
epoch67: step100/160
step 0: accuracy:0.12800000607967377, confidence:0.869041383266449, loss:8.526823997497559
epoch68: step0/160
step 6800: accuracy:0.12399999797344208, confidence:0.8807483315467834, loss:8.586867332458496
epoch68: step100/160
step 0: accuracy:0.1459999978542328, confidence:0.8644818067550659, loss:8.098711013793945
epoch69: step0/160
step 6900: accuracy:0.1550000011920929, confidence:0.878852903842926, loss:8.177667617797852
epoch69: step100/160
step 0: accuracy:0.12099999934434891, confidence:0.8763445019721985, loss:8.46329116821289
epoch70: step0/160
step 7000: accuracy:0.13300000131130219, confidence:0.881935179233551, loss:8.587621688842773
epoch70: step100/160
step 0: accuracy:0.12600000202655792, confidence:0.8800225853919983, loss:8.68586254119873
epoch71: step0/160
step 7100: accuracy:0.12099999934434891, confidence:0.8776124119758606, loss:8.59495735168457
epoch71: step100/160
step 0: accuracy:0.1550000011920929, confidence:0.8691675662994385, loss:8.066783905029297
epoch72: step0/160
step 7200: accuracy:0.12399999797344208, confidence:0.8746039271354675, loss:8.593167304992676
epoch72: step100/160
step 0: accuracy:0.13199999928474426, confidence:0.8746997714042664, loss:8.691486358642578
epoch73: step0/160
step 7300: accuracy:0.13699999451637268, confidence:0.8760385513305664, loss:8.657000541687012
epoch73: step100/160
step 0: accuracy:0.13699999451637268, confidence:0.8723775744438171, loss:8.364521026611328
epoch74: step0/160
step 7400: accuracy:0.1509999930858612, confidence:0.8932185769081116, loss:8.76476001739502
epoch74: step100/160
step 0: accuracy:0.13899999856948853, confidence:0.8605509400367737, loss:8.21520709991455
epoch75: step0/160
step 7500: accuracy:0.12800000607967377, confidence:0.8815943002700806, loss:8.844892501831055
epoch75: step100/160
step 0: accuracy:0.13899999856948853, confidence:0.8680732846260071, loss:8.3042631149292
epoch76: step0/160
step 7600: accuracy:0.1379999965429306, confidence:0.8806372880935669, loss:8.741267204284668
epoch76: step100/160
step 0: accuracy:0.12800000607967377, confidence:0.8648410439491272, loss:8.40864372253418
epoch77: step0/160
step 7700: accuracy:0.14300000667572021, confidence:0.9004900455474854, loss:8.959281921386719
epoch77: step100/160
step 0: accuracy:0.15600000321865082, confidence:0.9093009233474731, loss:8.983311653137207
epoch78: step0/160
step 7800: accuracy:0.12200000137090683, confidence:0.8845326900482178, loss:8.998769760131836
epoch78: step100/160
step 0: accuracy:0.15399999916553497, confidence:0.8362016081809998, loss:7.708099842071533
epoch79: step0/160
step 7900: accuracy:0.13199999928474426, confidence:0.8618165850639343, loss:8.203238487243652
epoch79: step100/160
step 0: accuracy:0.12300000339746475, confidence:0.8537472486495972, loss:8.028623580932617
epoch80: step0/160
step 8000: accuracy:0.14499999582767487, confidence:0.8715499043464661, loss:7.857193470001221
epoch80: step100/160
step 0: accuracy:0.11900000274181366, confidence:0.8650727272033691, loss:8.272086143493652
epoch81: step0/160
step 8100: accuracy:0.14100000262260437, confidence:0.8758034706115723, loss:8.14151668548584
epoch81: step100/160
step 0: accuracy:0.12800000607967377, confidence:0.8688117265701294, loss:8.138787269592285
epoch82: step0/160
step 8200: accuracy:0.13699999451637268, confidence:0.8767513632774353, loss:8.083905220031738
epoch82: step100/160
step 0: accuracy:0.09399999678134918, confidence:0.862224280834198, loss:8.48974895477295
epoch83: step0/160
step 8300: accuracy:0.125, confidence:0.8816089034080505, loss:8.353106498718262
epoch83: step100/160
step 0: accuracy:0.1289999932050705, confidence:0.8731389045715332, loss:8.350278854370117
epoch84: step0/160
step 8400: accuracy:0.12200000137090683, confidence:0.8825852274894714, loss:8.666254997253418
epoch84: step100/160
step 0: accuracy:0.11599999666213989, confidence:0.8651531934738159, loss:8.326910972595215
epoch85: step0/160
step 8500: accuracy:0.11900000274181366, confidence:0.8831924200057983, loss:8.572863578796387
epoch85: step100/160
step 0: accuracy:0.11599999666213989, confidence:0.8641021251678467, loss:8.651611328125
epoch86: step0/160
step 8600: accuracy:0.1340000033378601, confidence:0.8846750855445862, loss:8.50751781463623
epoch86: step100/160
step 0: accuracy:0.13600000739097595, confidence:0.8663387894630432, loss:8.169926643371582
epoch87: step0/160
step 8700: accuracy:0.11599999666213989, confidence:0.8874242901802063, loss:8.949499130249023
epoch87: step100/160
step 0: accuracy:0.13199999928474426, confidence:0.8716776371002197, loss:8.336833000183105
epoch88: step0/160
step 8800: accuracy:0.12800000607967377, confidence:0.8757291436195374, loss:8.633964538574219
epoch88: step100/160
step 0: accuracy:0.1459999978542328, confidence:0.8778345584869385, loss:8.233126640319824
epoch89: step0/160
step 8900: accuracy:0.11800000071525574, confidence:0.885182797908783, loss:8.783931732177734
epoch89: step100/160
step 0: accuracy:0.11599999666213989, confidence:0.8821285963058472, loss:8.88664436340332
epoch90: step0/160
step 9000: accuracy:0.14900000393390656, confidence:0.8772687315940857, loss:8.520787239074707
epoch90: step100/160
step 0: accuracy:0.11999999731779099, confidence:0.8670706748962402, loss:8.58963394165039
epoch91: step0/160
step 9100: accuracy:0.14000000059604645, confidence:0.8911104202270508, loss:8.85264778137207
epoch91: step100/160
step 0: accuracy:0.13199999928474426, confidence:0.8831565976142883, loss:8.672591209411621
epoch92: step0/160
step 9200: accuracy:0.13199999928474426, confidence:0.8900892734527588, loss:8.719378471374512
epoch92: step100/160
step 0: accuracy:0.14399999380111694, confidence:0.8790539503097534, loss:8.44742488861084
epoch93: step0/160
step 9300: accuracy:0.14800000190734863, confidence:0.9001419544219971, loss:8.717907905578613
epoch93: step100/160
step 0: accuracy:0.13099999725818634, confidence:0.8767673969268799, loss:8.393577575683594
epoch94: step0/160
step 9400: accuracy:0.1340000033378601, confidence:0.8803308010101318, loss:8.837145805358887
epoch94: step100/160
step 0: accuracy:0.1340000033378601, confidence:0.868454098701477, loss:8.345498085021973
epoch95: step0/160
step 9500: accuracy:0.12600000202655792, confidence:0.8894139528274536, loss:9.134294509887695
epoch95: step100/160
step 0: accuracy:0.14300000667572021, confidence:0.8806443810462952, loss:8.621964454650879
epoch96: step0/160
step 9600: accuracy:0.14300000667572021, confidence:0.902050256729126, loss:8.980863571166992
epoch96: step100/160
step 0: accuracy:0.1459999978542328, confidence:0.8855062127113342, loss:8.486945152282715
epoch97: step0/160
step 9700: accuracy:0.11299999803304672, confidence:0.8804450631141663, loss:9.252872467041016
epoch97: step100/160
step 0: accuracy:0.1379999965429306, confidence:0.8757351040840149, loss:8.53477954864502
epoch98: step0/160
step 9800: accuracy:0.14000000059604645, confidence:0.8917768001556396, loss:8.861624717712402
epoch98: step100/160
step 0: accuracy:0.11999999731779099, confidence:0.8762787580490112, loss:8.960129737854004
epoch99: step0/160
step 9900: accuracy:0.1469999998807907, confidence:0.885282576084137, loss:8.837793350219727
epoch99: step100/160
